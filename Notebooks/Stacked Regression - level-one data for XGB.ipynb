{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#life of property\n",
    "properties['N-life'] = 2018 - properties['yearbuilt']\n",
    "\n",
    "#error in calculation of the finished living area of home\n",
    "properties['N-LivingAreaError'] = properties['calculatedfinishedsquarefeet']/properties['finishedsquarefeet12']\n",
    "\n",
    "#proportion of living area\n",
    "properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "properties['N-LivingAreaProp2'] = properties['finishedsquarefeet12']/properties['finishedsquarefeet15']\n",
    "\n",
    "#Amout of extra space\n",
    "properties['N-ExtraSpace'] = properties['lotsizesquarefeet'] - properties['calculatedfinishedsquarefeet'] \n",
    "properties['N-ExtraSpace-2'] = properties['finishedsquarefeet15'] - properties['finishedsquarefeet12'] \n",
    "\n",
    "#Total number of rooms\n",
    "properties['N-TotalRooms'] = properties['bathroomcnt']*properties['bedroomcnt']\n",
    "\n",
    "#Average room size\n",
    "properties['N-AvRoomSize'] = properties['calculatedfinishedsquarefeet']/properties['roomcnt'] \n",
    "\n",
    "# Number of Extra rooms\n",
    "properties['N-ExtraRooms'] = properties['roomcnt'] - properties['N-TotalRooms'] \n",
    "\n",
    "#Ratio of the built structure value to land area\n",
    "properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "#Does property have a garage, pool or hot tub and AC?\n",
    "properties['N-GarPoolAC'] = ((properties['garagecarcnt']>0) & (properties['pooltypeid10']>0) & (properties['airconditioningtypeid']!=5))*1 \n",
    "\n",
    "properties[\"N-location\"] = properties[\"latitude\"] + properties[\"longitude\"]\n",
    "properties[\"N-location-2\"] = properties[\"latitude\"]*properties[\"longitude\"]\n",
    "properties[\"N-location-2round\"] = properties[\"N-location-2\"].round(-4)\n",
    "\n",
    "properties[\"N-latitude-round\"] = properties[\"latitude\"].round(-4)\n",
    "properties[\"N-longitude-round\"] = properties[\"longitude\"].round(-4)\n",
    "\n",
    "#Ratio of tax of property over parcel\n",
    "properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']\n",
    "\n",
    "#TotalTaxScore\n",
    "properties['N-TaxScore'] = properties['taxvaluedollarcnt']*properties['taxamount']\n",
    "\n",
    "#polnomials of tax delinquency year\n",
    "properties[\"N-taxdelinquencyyear-2\"] = properties[\"taxdelinquencyyear\"] ** 2\n",
    "properties[\"N-taxdelinquencyyear-3\"] = properties[\"taxdelinquencyyear\"] ** 3\n",
    "\n",
    "#Length of time since unpaid taxes\n",
    "properties['N-life'] = 2018 - properties['taxdelinquencyyear']\n",
    "\n",
    "#Number of properties in the zip\n",
    "zip_count = properties['regionidzip'].value_counts().to_dict()\n",
    "properties['N-zip_count'] = properties['regionidzip'].map(zip_count)\n",
    "\n",
    "#Number of properties in the city\n",
    "city_count = properties['regionidcity'].value_counts().to_dict()\n",
    "properties['N-city_count'] = properties['regionidcity'].map(city_count)\n",
    "\n",
    "#Number of properties in the city\n",
    "region_count = properties['regionidcounty'].value_counts().to_dict()\n",
    "properties['N-county_count'] = properties['regionidcounty'].map(region_count)\n",
    "\n",
    "#Average structuretaxvaluedollarcnt by city\n",
    "group = properties.groupby('regionidcity')['structuretaxvaluedollarcnt'].aggregate('mean').to_dict()\n",
    "properties['N-Avg-structuretaxvaluedollarcnt'] = properties['regionidcity'].map(group)\n",
    "\n",
    "#Deviation away from average\n",
    "properties['N-Dev-structuretaxvaluedollarcnt'] = (abs((properties['structuretaxvaluedollarcnt'] \n",
    "                                                       - properties['N-Avg-structuretaxvaluedollarcnt']))\n",
    "                                                  /properties['N-Avg-structuretaxvaluedollarcnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')\n",
    "data['wts_oct'] = np.where(data['month'] == 10, 1.25, 1)\n",
    "data['wts_nov'] = np.where(data['month'] == 11, 1.25, 1)\n",
    "data['wts_dec'] = np.where(data['month'] == 12, 1.25, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['bathroomcnt','bedroomcnt','buildingqualitytypeid','calculatedbathnbr','finishedfloor1squarefeet',\n",
    "           'calculatedfinishedsquarefeet','finishedsquarefeet12','finishedsquarefeet13',\n",
    "           'finishedsquarefeet15','finishedsquarefeet50','finishedsquarefeet6','fireplacecnt',\n",
    "           'fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude','lotsizesquarefeet',\n",
    "           'poolcnt','poolsizesum','censustractandblock','roomcnt','threequarterbathnbr','unitcnt',\n",
    "           'yardbuildingsqft17','yardbuildingsqft26','numberofstories',\n",
    "            'structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount',\n",
    "           'N-ValueRatio', 'N-LivingAreaProp', 'N-ValueProp', 'N-Dev-structuretaxvaluedollarcnt', \n",
    "            'N-TaxScore', 'N-zip_count', 'N-Avg-structuretaxvaluedollarcnt', 'N-city_count',\n",
    "           'N-LivingAreaProp2', 'N-location-2round', 'N-TotalRooms','N-AvRoomSize']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid','architecturalstyletypeid',\n",
    "           'buildingclasstypeid','heatingorsystemtypeid','pooltypeid10','pooltypeid2',\n",
    "            'pooltypeid7','propertylandusetypeid','regionidcounty',\n",
    "           'storytypeid','typeconstructiontypeid','yearbuilt','fireplaceflag',\n",
    "           'taxdelinquencyflag']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [2061,3101,1286],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom transformer, which selects certain variables\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, desired_cols):\n",
    "        self.desired_cols = desired_cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.desired_cols].values\n",
    "\n",
    "# A custom transformer, which first selects the categorical variables\n",
    "# from the DataFrame and then performs the dummification\n",
    "class DF_Selector_GetDummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_dict):\n",
    "        self.cat_dict = cat_dict\n",
    "        self.ndummies = sum(len(c) - 1  for c in cat_dict.values()) \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.fillna(-1) # missing values are given -1 missing label\n",
    "        foo = np.zeros((X.shape[0],self.ndummies))\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for c in sorted(self.cat_dict.keys()):\n",
    "            end += len(self.cat_dict[c]) - 1\n",
    "            foo[:, start:end] = pd.get_dummies(X[c].astype('category', categories=self.cat_dict[c]))[self.cat_dict[c][1:]]\n",
    "            start += len(self.cat_dict[c]) - 1\n",
    "        return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into the 10-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24283, 53623, 10038, ..., 66037, 55934, 86364])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "np.random.shuffle(indices) # in-place shuffling \n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_indices = {(i+1):indices[i::10] for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([24283, 81578, 55185, ..., 88696, 19420, 22584]),\n",
       " 2: array([53623, 89226, 14417, ..., 80106, 39259, 65462]),\n",
       " 3: array([10038, 42930, 25710, ..., 25406, 50805, 66037]),\n",
       " 4: array([ 6560, 52504, 69020, ..., 44509, 61176, 55934]),\n",
       " 5: array([72110, 88930, 66005, ..., 46008, 10481, 86364]),\n",
       " 6: array([85819, 15175, 52495, ..., 36792, 36810, 62760]),\n",
       " 7: array([12329, 52468, 49812, ..., 18561, 36027, 88635]),\n",
       " 8: array([64150, 73168, 74499, ..., 69304, 24814, 70209]),\n",
       " 9: array([87434, 67401, 85581, ..., 71894, 82876,  5014]),\n",
       " 10: array([31642, 81045, 14458, ...,  6418, 81792, 42747])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models on the 10 splits of data \\ fold_i for i = 1,...,10 & obtaining level 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet13', 'fi... 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017], 'pooltypeid2': [-1, 0, 1]}))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...working on fold 1\n",
      "......training model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b829fd98cbe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     reg = XGBRegressor(random_state=42, n_estimators=600, max_depth=4, learning_rate=0.02,\n\u001b[0;32m     15\u001b[0m                           subsample= 1, colsample_bytree= 1)\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_traindata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_traindata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logerror'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# level-one data (i.e., predict observations on current fold using reg)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anerdi/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    291\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                               verbose_eval=verbose)\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anerdi/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anerdi/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anerdi/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 886\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    887\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "level_one_data = data[['parcelid']].copy()\n",
    "\n",
    "# initialize an NoneObject to be a placeholder for level-one data for current model\n",
    "model_preds = None \n",
    "\n",
    "current_model_name = \"XGB\"\n",
    "for fold_nbr in range(1,11):  \n",
    "    print(\"...working on fold %d\" % fold_nbr)\n",
    "    # set training data X \\ fold\n",
    "    current_traindata = data.iloc[np.setdiff1d(indices,fold_indices[fold_nbr]),]\n",
    "\n",
    "    # get a clone of the model and fit the current training data\n",
    "    print('......training model')\n",
    "    reg = XGBRegressor(random_state=42, n_estimators=600, max_depth=4, learning_rate=0.02,\n",
    "                          subsample= 1, colsample_bytree= 1)\n",
    "    reg.fit(feature_pipeline.transform(current_traindata), current_traindata['logerror'])\n",
    "\n",
    "    # level-one data (i.e., predict observations on current fold using reg)\n",
    "    print('......obtaining level-one data')\n",
    "    fold_data = data.iloc[fold_indices[fold_nbr]]\n",
    "    fold_preds = Series(reg.predict(feature_pipeline.transform(fold_data)), \n",
    "                        index=fold_indices[fold_nbr], name = current_model_name)\n",
    "\n",
    "    # adding to the placeholder for level-one data\n",
    "    if model_preds is not None:\n",
    "        model_preds = pd.concat([model_preds, fold_preds])\n",
    "    else:\n",
    "        model_preds = fold_preds\n",
    "\n",
    "    # some housecleaning\n",
    "    del reg\n",
    "\n",
    "# add level-one predictions of current model to running dataframe\n",
    "level_one_data = pd.concat([level_one_data, model_preds], axis=1)\n",
    "    \n",
    "print(\"all done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ridge</th>\n",
       "      <th>enet</th>\n",
       "      <th>lasso</th>\n",
       "      <th>larm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17073783</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.010857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17088994</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17100444</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.010079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17102429</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.011320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17109604</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.012941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid     ridge      enet     lasso      larm\n",
       "0  17073783  0.017901  0.010024  0.010388  0.010857\n",
       "1  17088994  0.010651  0.006399  0.007616  0.009479\n",
       "2  17100444  0.008782  0.008610  0.008853  0.010079\n",
       "3  17102429  0.014618  0.012370  0.012010  0.011320\n",
       "4  17109604  0.018050  0.016426  0.015855  0.012941"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_one_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
