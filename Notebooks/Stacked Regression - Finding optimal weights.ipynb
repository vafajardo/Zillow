{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import feature_pipelines as pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test_probs(model, col_names=None, type = None):\n",
    "    model_preds = None\n",
    "#     change month of properties\n",
    "#     properties['month'] = month\n",
    "    for i in range(int(properties.shape[0] / 100000)):   \n",
    "        # get current test features\n",
    "        current_test_feats = feature_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "\n",
    "        # predict on current test obs\n",
    "        current_preds = DataFrame(model.predict_proba(current_test_feats), columns=col_names,\n",
    "                              index = np.arange(i*100000,(i+1)*100000))\n",
    "\n",
    "        if model_preds is not None:\n",
    "            model_preds = pd.concat([model_preds, current_preds])\n",
    "        else:\n",
    "            model_preds = current_preds\n",
    "\n",
    "    #  fencepost problem\n",
    "    current_test_feats = feature_pipeline.transform(properties.iloc[2900000:])\n",
    "    # predict on current test obs\n",
    "    current_preds = DataFrame(model.predict_proba(current_test_feats), columns=col_names,\n",
    "                             index = np.arange(2900000,2985217))\n",
    "    model_preds = pd.concat([model_preds, current_preds])\n",
    "#     del properties['month']\n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "# create data DataFrame\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#proportion of living area\n",
    "properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "\n",
    "properties['N-NonLivingAreaProp'] = properties['garagetotalsqft']/properties['lotsizesquarefeet']\n",
    "\n",
    "#Ratio of the built structure value to land area\n",
    "properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "#Ratio of tax of property over parcel\n",
    "properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']\n",
    "\n",
    "# Pool\n",
    "properties['poolsizesum'] = properties['poolsizesum'].fillna(0)\n",
    "# properties['Pool'] = (properties['poolsizesum'] > 0).astype(int)\n",
    "properties['Pool'] = (properties['pooltypeid2'].fillna(0) + properties['pooltypeid7'].fillna(0)).astype(int)\n",
    "\n",
    "properties['regionidcounty'] = properties['regionidcounty'].fillna(9999)\n",
    "\n",
    "# some more feature engineering\n",
    "properties['age'] = 2017 - properties['yearbuilt']\n",
    "properties['additional_rooms_count'] = np.maximum((properties['roomcnt'].values \n",
    "                                                   - properties['calculatedbathnbr'].values\n",
    "                                                   - properties['bedroomcnt'].values),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['bedroomcnt','calculatedbathnbr','age','additional_rooms_count',\n",
    "           'calculatedfinishedsquarefeet','fullbathcnt','garagecarcnt','garagetotalsqft',\n",
    "            'latitude','longitude','lotsizesquarefeet', 'roomcnt',\n",
    "           'numberofstories','structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount',\n",
    "           'N-ValueRatio', 'N-LivingAreaProp', 'N-NonLivingAreaProp','N-ValueProp']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid','architecturalstyletypeid',\n",
    "           'buildingclasstypeid','heatingorsystemtypeid','Pool','propertylandusetypeid','regionidcounty',\n",
    "           'storytypeid','typeconstructiontypeid','fireplaceflag','taxdelinquencyflag']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [2061,3101,1286],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', pipes.DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', pipes.DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing num_atts per regionid\n",
    "for countyid in properties.regionidcounty.unique():\n",
    "    # setup condition\n",
    "    cond = properties['regionidcounty'] == countyid\n",
    "    indices = np.where(cond)[0]\n",
    "    # impute values based on region\n",
    "    if countyid != 9999:\n",
    "        properties.loc[indices,num_atts] = (properties.loc[indices,num_atts]\n",
    "                                .fillna(properties.loc[indices,num_atts]\n",
    "                                .apply(np.mean)))\n",
    "    else:\n",
    "        properties.loc[indices,num_atts] = (properties.loc[indices,num_atts]\n",
    "                                            .fillna(properties[num_atts]\n",
    "                                            .apply(np.mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert properties[num_atts].isnull().any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['bedroomcnt', 'calculatedbathnbr', 'age', 'additional_rooms_count', 'calculatedfinishedsquarefeet', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'latitude', 'longitude', 'lotsizesqu...'typeconstructiontypeid': [-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]}))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in level-one data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1data_rfs = pd.read_csv(\"/home/anerdi/Desktop/Zillow/levelonedata/l1data_twostage_rfs_age.csv.gz\")\n",
    "# l1data_rfs_last_fold = pd.read_csv(\"/home/anerdi/Desktop/Zillow/levelonedata/l1data_twostage_rfs_last_fold.csv.gz\")\n",
    "# l1data_rfs[~l1data_rfs_last_fold.isnull().any(axis=1)] = l1data_rfs_last_fold[~l1data_rfs_last_fold.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1data_linear_models = pd.read_csv(\"/home/anerdi/Desktop/Zillow/levelonedata/l1data_twostage_linear_models_age.csv.gz\")\n",
    "# l1data_linear_models_last_fold = pd.read_csv(\"/home/anerdi/Desktop/Zillow/levelonedata/l1data_twostage_linear_models_last_fold.csv.gz\")\n",
    "# l1data_linear_models[~l1data_linear_models_last_fold.isnull().any(axis=1)] = l1data_linear_models_last_fold[~l1data_linear_models_last_fold.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert l1data_rfs.isnull().any().any() == False\n",
    "assert l1data_linear_models.isnull().any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (l1data_linear_models.parcelid == l1data_rfs.parcelid).all()\n",
    "assert (l1data_linear_models.parcelid == data.parcelid).all()\n",
    "assert l1data_linear_models.shape[0] == data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1data = pd.concat([l1data_linear_models, l1data_rfs.iloc[:,1:], data[['logerror']]], axis=1)\n",
    "# l1data = pd.merge(l1data, data[['parcelid','logerror']], on = 'parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>stacked_rfs_ridge</th>\n",
       "      <th>stacked_rfs_enet</th>\n",
       "      <th>stacked_rfs_lasso</th>\n",
       "      <th>stacked_rfs_larm</th>\n",
       "      <th>stacked_rfs_huber</th>\n",
       "      <th>stacked_annrfs_ridge</th>\n",
       "      <th>stacked_annrfs_enet</th>\n",
       "      <th>stacked_annrfs_lasso</th>\n",
       "      <th>stacked_annrfs_larm</th>\n",
       "      <th>...</th>\n",
       "      <th>stacked_rfs_rf_maxdepth8</th>\n",
       "      <th>stacked_rfs_rf_maxdepth10</th>\n",
       "      <th>stacked_rfs_rf_maxdepth12</th>\n",
       "      <th>stacked_annrfs_rf_maxdepth8</th>\n",
       "      <th>stacked_annrfs_rf_maxdepth10</th>\n",
       "      <th>stacked_annrfs_rf_maxdepth12</th>\n",
       "      <th>logistic_rf_maxdepth8</th>\n",
       "      <th>logistic_rf_maxdepth10</th>\n",
       "      <th>logistic_rf_maxdepth12</th>\n",
       "      <th>logerror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17073783</td>\n",
       "      <td>0.026642</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.027531</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17088994</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17100444</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.020932</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.027659</td>\n",
       "      <td>0.026147</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17102429</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>0.017084</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.026112</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>0.023709</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.019883</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.020995</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.013383</td>\n",
       "      <td>-0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17109604</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.018409</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  stacked_rfs_ridge  stacked_rfs_enet  stacked_rfs_lasso  \\\n",
       "0  17073783           0.026642          0.026500           0.026087   \n",
       "1  17088994           0.008293          0.009277           0.009200   \n",
       "2  17100444           0.022774          0.021773           0.020932   \n",
       "3  17102429           0.017750          0.017539           0.017084   \n",
       "4  17109604           0.018645          0.018092           0.017843   \n",
       "\n",
       "   stacked_rfs_larm  stacked_rfs_huber  stacked_annrfs_ridge  \\\n",
       "0          0.027531           0.009768              0.021656   \n",
       "1          0.007287           0.003119              0.010055   \n",
       "2          0.011867           0.001351              0.027659   \n",
       "3          0.010695           0.001707              0.026112   \n",
       "4          0.015738           0.013915              0.016518   \n",
       "\n",
       "   stacked_annrfs_enet  stacked_annrfs_lasso  stacked_annrfs_larm    ...     \\\n",
       "0             0.021685              0.021387             0.021477    ...      \n",
       "1             0.011050              0.010974             0.009521    ...      \n",
       "2             0.026147              0.024698             0.016643    ...      \n",
       "3             0.025017              0.023709             0.019355    ...      \n",
       "4             0.015872              0.015628             0.013343    ...      \n",
       "\n",
       "   stacked_rfs_rf_maxdepth8  stacked_rfs_rf_maxdepth10  \\\n",
       "0                  0.026900                   0.024892   \n",
       "1                  0.006175                   0.006116   \n",
       "2                  0.014502                   0.012973   \n",
       "3                  0.011784                   0.011442   \n",
       "4                  0.015035                   0.015901   \n",
       "\n",
       "   stacked_rfs_rf_maxdepth12  stacked_annrfs_rf_maxdepth8  \\\n",
       "0                   0.026428                     0.020637   \n",
       "1                   0.005256                     0.008567   \n",
       "2                   0.014187                     0.018923   \n",
       "3                   0.013102                     0.019883   \n",
       "4                   0.015612                     0.012726   \n",
       "\n",
       "   stacked_annrfs_rf_maxdepth10  stacked_annrfs_rf_maxdepth12  \\\n",
       "0                      0.018499                      0.019837   \n",
       "1                      0.008466                      0.007555   \n",
       "2                      0.017378                      0.018522   \n",
       "3                      0.019471                      0.020995   \n",
       "4                      0.013686                      0.013483   \n",
       "\n",
       "   logistic_rf_maxdepth8  logistic_rf_maxdepth10  logistic_rf_maxdepth12  \\\n",
       "0               0.019777                0.017621                0.018932   \n",
       "1               0.011739                0.011584                0.010603   \n",
       "2               0.006619                0.005120                0.006457   \n",
       "3               0.012073                0.011728                0.013383   \n",
       "4               0.017651                0.018409                0.018022   \n",
       "\n",
       "   logerror  \n",
       "0    0.0953  \n",
       "1    0.0198  \n",
       "2    0.0060  \n",
       "3   -0.0566  \n",
       "4    0.0573  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parcelid\n",
      "stacked_rfs_ridge\n",
      "stacked_rfs_enet\n",
      "stacked_rfs_lasso\n",
      "stacked_rfs_larm\n",
      "stacked_rfs_huber\n",
      "stacked_annrfs_ridge\n",
      "stacked_annrfs_enet\n",
      "stacked_annrfs_lasso\n",
      "stacked_annrfs_larm\n",
      "stacked_annrfs_huber\n",
      "logistic_ridge\n",
      "logistic_enet\n",
      "logistic_lasso\n",
      "logistic_larm\n",
      "logistic_huber\n",
      "stacked_rfs_rf_maxdepth8\n",
      "stacked_rfs_rf_maxdepth10\n",
      "stacked_rfs_rf_maxdepth12\n",
      "stacked_annrfs_rf_maxdepth8\n",
      "stacked_annrfs_rf_maxdepth10\n",
      "stacked_annrfs_rf_maxdepth12\n",
      "logistic_rf_maxdepth8\n",
      "logistic_rf_maxdepth10\n",
      "logistic_rf_maxdepth12\n",
      "logerror\n"
     ]
    }
   ],
   "source": [
    "for c in l1data.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic for finding weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stand Alones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up quadratic objective function\n",
    "X = l1data[['logistic_lasso', 'stacked_rfs_lasso', 'stacked_annrfs_lasso']].values\n",
    "y = l1data.logerror.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abserror = abs(X-np.tile(l1data.logerror.values[:,np.newaxis],X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wins = np.array([(abserror[:,i] == np.min(abserror, axis=1)).sum() for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33065633,  0.36485184,  0.30449183])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wins / wins.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = l1data[['stacked_annrfs_enet',\n",
    " 'stacked_annrfs_lasso',\n",
    " 'stacked_annrfs_rf_maxdepth8',\n",
    " 'stacked_annrfs_ridge',\n",
    " 'stacked_rfs_ridge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abserror = abs(X.values-np.tile(l1data.logerror.values[:,np.newaxis],X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07591249,  0.09201883,  0.25784547,  0.16796455,  0.40625865])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wins = np.array([(abserror[:,i] == np.min(abserror, axis=1)).sum() for i in range(X.shape[1])])\n",
    "wins/wins.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enet_wins = wins[::7].sum()\n",
    "# ridge_wins = wins[7::7].sum()\n",
    "# lasso_wins = wins[6:9].sum()\n",
    "# larm_wins = wins[9:12].sum()\n",
    "# huber_wins = wins[12:15].sum()\n",
    "# rf_wins = wins[15:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.array([ridge_wins, enet_wins, lasso_wins, larm_wins, huber_wins, rf_wins]) / wins.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding weights via classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newy = np.argmin(abserror, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=15, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (l1data.parcelid == data.parcelid).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(feature_pipeline.transform(data),newy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52674605372473005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(feature_pipeline.transform(data), newy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(feature_pipeline.transform(data)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using classifier to find weights for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_probs = generate_test_probs(clf, col_names= X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stacked_annrfs_enet</th>\n",
       "      <th>stacked_annrfs_lasso</th>\n",
       "      <th>stacked_annrfs_rf_maxdepth8</th>\n",
       "      <th>stacked_annrfs_ridge</th>\n",
       "      <th>stacked_rfs_ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124644</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.090185</td>\n",
       "      <td>0.357573</td>\n",
       "      <td>0.394960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141738</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.328742</td>\n",
       "      <td>0.408225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183933</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.261554</td>\n",
       "      <td>0.100823</td>\n",
       "      <td>0.421060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257326</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.330695</td>\n",
       "      <td>0.068147</td>\n",
       "      <td>0.328294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238848</td>\n",
       "      <td>0.041081</td>\n",
       "      <td>0.156981</td>\n",
       "      <td>0.192375</td>\n",
       "      <td>0.370715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stacked_annrfs_enet  stacked_annrfs_lasso  stacked_annrfs_rf_maxdepth8  \\\n",
       "0             0.124644              0.032638                     0.090185   \n",
       "1             0.141738              0.023277                     0.098019   \n",
       "2             0.183933              0.032630                     0.261554   \n",
       "3             0.257326              0.015538                     0.330695   \n",
       "4             0.238848              0.041081                     0.156981   \n",
       "\n",
       "   stacked_annrfs_ridge  stacked_rfs_ridge  \n",
       "0              0.357573           0.394960  \n",
       "1              0.328742           0.408225  \n",
       "2              0.100823           0.421060  \n",
       "3              0.068147           0.328294  \n",
       "4              0.192375           0.370715  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stacked_annrfs_enet</th>\n",
       "      <th>stacked_annrfs_lasso</th>\n",
       "      <th>stacked_annrfs_rf_maxdepth8</th>\n",
       "      <th>stacked_annrfs_ridge</th>\n",
       "      <th>stacked_rfs_ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.765218e-02</td>\n",
       "      <td>8.948346e-02</td>\n",
       "      <td>2.532114e-01</td>\n",
       "      <td>1.652891e-01</td>\n",
       "      <td>4.143639e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.325371e-02</td>\n",
       "      <td>6.468272e-02</td>\n",
       "      <td>1.074407e-01</td>\n",
       "      <td>7.290686e-02</td>\n",
       "      <td>7.589662e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.030303e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.888016e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.612953e-02</td>\n",
       "      <td>4.063128e-02</td>\n",
       "      <td>1.653123e-01</td>\n",
       "      <td>1.192126e-01</td>\n",
       "      <td>3.677362e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.775524e-02</td>\n",
       "      <td>7.187100e-02</td>\n",
       "      <td>2.326592e-01</td>\n",
       "      <td>1.681708e-01</td>\n",
       "      <td>4.255204e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.005334e-01</td>\n",
       "      <td>1.232688e-01</td>\n",
       "      <td>3.199874e-01</td>\n",
       "      <td>2.051817e-01</td>\n",
       "      <td>4.647585e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.358734e-01</td>\n",
       "      <td>7.717611e-01</td>\n",
       "      <td>7.743199e-01</td>\n",
       "      <td>7.732723e-01</td>\n",
       "      <td>8.732251e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stacked_annrfs_enet  stacked_annrfs_lasso  stacked_annrfs_rf_maxdepth8  \\\n",
       "count         2.985217e+06          2.985217e+06                 2.985217e+06   \n",
       "mean          7.765218e-02          8.948346e-02                 2.532114e-01   \n",
       "std           6.325371e-02          6.468272e-02                 1.074407e-01   \n",
       "min           0.000000e+00          0.000000e+00                 3.030303e-03   \n",
       "25%           3.612953e-02          4.063128e-02                 1.653123e-01   \n",
       "50%           5.775524e-02          7.187100e-02                 2.326592e-01   \n",
       "75%           1.005334e-01          1.232688e-01                 3.199874e-01   \n",
       "max           7.358734e-01          7.717611e-01                 7.743199e-01   \n",
       "\n",
       "       stacked_annrfs_ridge  stacked_rfs_ridge  \n",
       "count          2.985217e+06       2.985217e+06  \n",
       "mean           1.652891e-01       4.143639e-01  \n",
       "std            7.290686e-02       7.589662e-02  \n",
       "min            0.000000e+00       2.888016e-02  \n",
       "25%            1.192126e-01       3.677362e-01  \n",
       "50%            1.681708e-01       4.255204e-01  \n",
       "75%            2.051817e-01       4.647585e-01  \n",
       "max            7.732723e-01       8.732251e-01  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probs.to_csv(\"/home/anerdi/Desktop/Zillow/levelonedata/super_learner_weights_7.csv.gz\", compression='gzip',\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing performance of models with extreme points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xextreme = X[np.where((l1data.logerror <= -2) | (l1data.logerror >= 2))[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extreme_logerrors = l1data.iloc[np.where((l1data.logerror <= -2) | (l1data.logerror >= 2))[0],:].logerror.values[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extreme_abserror = abs(Xextreme-np.tile(extreme_logerrors,Xextreme.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.55365065,  2.54774629,  2.54912892,  2.5542268 ,  2.54937705,\n",
       "        2.55064732,  2.55432623,  2.54927759,  2.55057871,  2.55465447,\n",
       "        2.54918357,  2.55058782,  2.55315009,  2.55187126,  2.55255297,\n",
       "        2.55306334,  2.54588748])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_abserror.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal weights using NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcelid', 'stacked_rfs_ridge', 'stacked_rfs_enet',\n",
       "       'stacked_rfs_lasso', 'stacked_rfs_larm', 'stacked_rfs_huber',\n",
       "       'stacked_annrfs_ridge', 'stacked_annrfs_enet', 'stacked_annrfs_lasso',\n",
       "       'stacked_annrfs_larm', 'stacked_annrfs_huber', 'logistic_ridge',\n",
       "       'logistic_enet', 'logistic_lasso', 'logistic_larm', 'logistic_huber',\n",
       "       'stacked_rfs_rf', 'stacked_rfs_rf_overfit', 'stacked_annrfs_rf',\n",
       "       'stacked_annrfs_rf_overfit', 'logistic_rf', 'logistic_rf_overfit',\n",
       "       'logerror'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = l1data[[\n",
    "    'logistic_ridge',\n",
    " 'stacked_rfs_ridge',\n",
    " 'stacked_annrfs_ridge']].values\n",
    "\n",
    "y = l1data.logerror.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = MLPRegressor(hidden_layer_sizes=(10,10),random_state=9, max_iter=300, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=9, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = stack.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_submission = DataFrame({'ParcelId': l1data['parcelid'],\n",
    "                           '201610':preds,\n",
    "                           '201611':preds,\n",
    "                           '201612':preds,\n",
    "})\n",
    "new_submission['201710'] = 0\n",
    "new_submission['201711'] = 0\n",
    "new_submission['201712'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06241616765085067,\n",
       " 0.062246095856333956,\n",
       " 0.07335353272780508,\n",
       " 0.064614821512161927)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_errors(new_submission,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anerdi/Desktop/Zillow/submissions/stage2_stacked_NN_ridge.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(stack, '/home/anerdi/Desktop/Zillow/submissions/stage2_stacked_NN_ridge.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
