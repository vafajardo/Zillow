{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import feature_pipelines as pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_regression_preds(reg, model_name='pred_logerror'):\n",
    "    reg_preds = None\n",
    "    for i in range(int(properties.shape[0] / 100000)):   \n",
    "        # get current test features\n",
    "        current_test_feats = feature_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "\n",
    "        # predict on current test obs\n",
    "        current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                              index = np.arange(i*100000,(i+1)*100000))\n",
    "\n",
    "        if reg_preds is not None:\n",
    "            reg_preds = pd.concat([reg_preds, current_preds])\n",
    "        else:\n",
    "            reg_preds = current_preds\n",
    "\n",
    "    #  fencepost problem\n",
    "    current_test_feats = feature_pipeline.transform(properties.iloc[2900000:])\n",
    "    current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                          index = np.arange(2900000,2985217))\n",
    "    reg_preds = pd.concat([reg_preds, current_preds])\n",
    "    return reg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submissions(oct_model,nov_model,dec_model,name='new_submission',logy=True):\n",
    "    \"\"\"\n",
    "    This function creates the submission file for the public leaderboard predictions.\n",
    "    Three already fitted models, one for each of the predicting time points, is required.\n",
    "    \"\"\"\n",
    "    submission_df = DataFrame()\n",
    "    for i in range(int(properties.shape[0] / 100000)):\n",
    "        all_feats = full_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "        foo = properties.iloc[i*100000:(i+1)*100000][['parcelid']].reset_index(drop=True)\n",
    "        if logy:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                            '201611': nov_model.predict(all_feats),\n",
    "                                                            '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "        else:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': np.log(oct_model.predict(all_feats)),\n",
    "                                                            '201611': np.log(nov_model.predict(all_feats)),\n",
    "                                                            '201612': np.log(dec_model.predict(all_feats))})], axis=1)\n",
    "        submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "    #  fencepost problem\n",
    "    all_feats = full_pipeline.transform(properties.iloc[2900000:])\n",
    "    foo = properties.iloc[2900000:][['parcelid']].reset_index(drop=True)\n",
    "    foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                    '201611': nov_model.predict(all_feats),\n",
    "                                                    '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "    submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "    submission_df['201710'] = 0\n",
    "    submission_df['201711'] = 0\n",
    "    submission_df['201712'] = 0\n",
    "    \n",
    "    submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "#     submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "#                                                                                            '201710','201711','201712']].round(4)\n",
    "    # unit test\n",
    "    submission_df.drop_duplicates(inplace=True)\n",
    "    assert submission_df.shape[0] == properties.shape[0]\n",
    "    # write to .csv\n",
    "    submission_df[['ParcelId','201610','201611','201612',\n",
    "                  '201710','201711','201712']].to_csv(name + \".gz\", index=False, float_format='%.4g', compression='gzip')\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#proportion of living area\n",
    "properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "\n",
    "#Ratio of the built structure value to land area\n",
    "properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "#Ratio of tax of property over parcel\n",
    "properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']\n",
    "\n",
    "# Pool\n",
    "properties['Pool'] = (properties['pooltypeid2'].fillna(0) + properties['pooltypeid7'].fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')\n",
    "data['wts_xgb_oct'] = np.where(data['month'] == 10, 1.25, 1)\n",
    "data['wts_xgb_nov'] = np.where(data['month'] == 11, 1.25, 1)\n",
    "data['wts_xgb_dec'] = np.where(data['month'] == 12, 1.25, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data  Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['bathroomcnt','bedroomcnt','buildingqualitytypeid','calculatedbathnbr','finishedfloor1squarefeet',\n",
    "           'calculatedfinishedsquarefeet','finishedsquarefeet12','finishedsquarefeet13',\n",
    "           'finishedsquarefeet15','finishedsquarefeet50','finishedsquarefeet6','fireplacecnt',\n",
    "           'fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude','lotsizesquarefeet',\n",
    "           'poolcnt','poolsizesum','censustractandblock','roomcnt','threequarterbathnbr','unitcnt',\n",
    "           'yardbuildingsqft17','yardbuildingsqft26','numberofstories',\n",
    "            'structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount',\n",
    "           'N-ValueRatio', 'N-LivingAreaProp', 'N-ValueProp']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid','architecturalstyletypeid',\n",
    "           'buildingclasstypeid','heatingorsystemtypeid','pooltypeid10','pooltypeid2',\n",
    "            'pooltypeid7','propertylandusetypeid','regionidcounty',\n",
    "           'storytypeid','typeconstructiontypeid','yearbuilt','fireplaceflag',\n",
    "           'taxdelinquencyflag']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [2061,3101,1286],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', pipes.DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', pipes.DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet13', 'fi...013, 2014, 2015, 2016, 2017], 'pooltypeid7': [-1, 0, 1], 'taxdelinquencyflag': [-1, 'Y', 'N']}))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(data) #fitting the pipeline to the entire properties dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_overestimated = np.where(data['logerror'] >= 0)[0]\n",
    "ix_underestimated = np.where(data['logerror'] < 0)[0]\n",
    "data_indices = {\"over\": ix_overestimated, \"under\": ix_underestimated}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert ix_overestimated.shape[0] + ix_underestimated.shape[0] == data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"xgb_oct\",XGBRegressor(random_state=42, n_estimators=400, max_depth=3, learning_rate=0.02,\n",
    "                          subsample= 1, colsample_bytree= 1)),\n",
    "    (\"xgb_nov\",XGBRegressor(random_state=42, n_estimators=400, max_depth=3, learning_rate=0.02,\n",
    "                          subsample= 1, colsample_bytree= 1)),\n",
    "    (\"xgb_dec\",XGBRegressor(random_state=42, n_estimators=400, max_depth=3, learning_rate=0.02,\n",
    "                          subsample= 1, colsample_bytree= 1)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: xgb_oct\n",
      "Current model: xgb_nov\n",
      "Current model: xgb_dec\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\", usecols=['parcelid'])\n",
    "\n",
    "for pair in models:\n",
    "    current_model_name,current_model = pair\n",
    "    print(\"Current model: %s\" % current_model_name)\n",
    "    \n",
    "    for key,val in data_indices.items():\n",
    "        type_of_zestimate, ix = key, val\n",
    "\n",
    "        # preprocess current training data\n",
    "        current_traindata = data.iloc[ix,]\n",
    "\n",
    "        # get a clone of the model and fit the current training data\n",
    "        reg = clone(current_model)\n",
    "        reg.fit(feature_pipeline.transform(current_traindata), current_traindata['logerror'],\n",
    "               sample_weight = current_traindata['wts_%s' % current_model_name])\n",
    "\n",
    "        # obtain predictions on test set\n",
    "        reg_preds = generate_regression_preds(reg, model_name=\"%s_%s\" % (current_model_name,type_of_zestimate))\n",
    "        test_predictions = pd.concat([test_predictions, reg_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>xgb_oct_under</th>\n",
       "      <th>xgb_oct_over</th>\n",
       "      <th>xgb_nov_under</th>\n",
       "      <th>xgb_nov_over</th>\n",
       "      <th>xgb_dec_under</th>\n",
       "      <th>xgb_dec_over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.198943</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>-0.209733</td>\n",
       "      <td>0.085679</td>\n",
       "      <td>-0.193651</td>\n",
       "      <td>0.087517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.110940</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>-0.114238</td>\n",
       "      <td>0.079867</td>\n",
       "      <td>-0.110725</td>\n",
       "      <td>0.081849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>-0.269981</td>\n",
       "      <td>0.624938</td>\n",
       "      <td>-0.287432</td>\n",
       "      <td>0.675193</td>\n",
       "      <td>-0.259808</td>\n",
       "      <td>0.618806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.487692</td>\n",
       "      <td>-0.223898</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>-0.199660</td>\n",
       "      <td>0.479048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>-0.282351</td>\n",
       "      <td>0.271146</td>\n",
       "      <td>-0.286560</td>\n",
       "      <td>0.225149</td>\n",
       "      <td>-0.333289</td>\n",
       "      <td>0.256966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  xgb_oct_under  xgb_oct_over  xgb_nov_under  xgb_nov_over  \\\n",
       "0  10754147      -0.198943      0.087975      -0.209733      0.085679   \n",
       "1  10759547      -0.110940      0.081205      -0.114238      0.079867   \n",
       "2  10843547      -0.269981      0.624938      -0.287432      0.675193   \n",
       "3  10859147      -0.224659      0.487692      -0.223898      0.511500   \n",
       "4  10879947      -0.282351      0.271146      -0.286560      0.225149   \n",
       "\n",
       "   xgb_dec_under  xgb_dec_over  \n",
       "0      -0.193651      0.087517  \n",
       "1      -0.110725      0.081849  \n",
       "2      -0.259808      0.618806  \n",
       "3      -0.199660      0.479048  \n",
       "4      -0.333289      0.256966  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions.to_csv(\"/home/anerdi/Desktop/Zillow/twostagemodel/XGB-two-stage-preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overestimate_probabilities = pd.read_csv(\"/home/anerdi/Desktop/Zillow/twostagemodel/overestimate_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>overestimate_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.509328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0.507312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.689618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.543763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  overestimate_prob\n",
       "0  10754147           0.509328\n",
       "1  10759547           0.507312\n",
       "2  10843547           1.000000\n",
       "3  10859147           0.689618\n",
       "4  10879947           0.543763"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overestimate_probabilities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = pd.merge(test_predictions, overestimate_probabilities, on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pair in models:\n",
    "    current_model_name, current_model = pair\n",
    "    # combine over and under to get prediction\n",
    "    test_predictions[current_model_name] = (test_predictions['%s_over' % current_model_name]*test_predictions['overestimate_prob'] +\n",
    "                    test_predictions['%s_under' % current_model_name]*(1 - test_predictions['overestimate_prob']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>xgb_oct_under</th>\n",
       "      <th>xgb_oct_over</th>\n",
       "      <th>xgb_nov_under</th>\n",
       "      <th>xgb_nov_over</th>\n",
       "      <th>xgb_dec_under</th>\n",
       "      <th>xgb_dec_over</th>\n",
       "      <th>overestimate_prob</th>\n",
       "      <th>xgb_oct</th>\n",
       "      <th>xgb_nov</th>\n",
       "      <th>xgb_dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.198943</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>-0.209733</td>\n",
       "      <td>0.085679</td>\n",
       "      <td>-0.193651</td>\n",
       "      <td>0.087517</td>\n",
       "      <td>0.509328</td>\n",
       "      <td>-0.052808</td>\n",
       "      <td>-0.059271</td>\n",
       "      <td>-0.050444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.110940</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>-0.114238</td>\n",
       "      <td>0.079867</td>\n",
       "      <td>-0.110725</td>\n",
       "      <td>0.081849</td>\n",
       "      <td>0.507312</td>\n",
       "      <td>-0.013462</td>\n",
       "      <td>-0.015767</td>\n",
       "      <td>-0.013030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>-0.269981</td>\n",
       "      <td>0.624938</td>\n",
       "      <td>-0.287432</td>\n",
       "      <td>0.675193</td>\n",
       "      <td>-0.259808</td>\n",
       "      <td>0.618806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624938</td>\n",
       "      <td>0.675193</td>\n",
       "      <td>0.618806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.487692</td>\n",
       "      <td>-0.223898</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>-0.199660</td>\n",
       "      <td>0.479048</td>\n",
       "      <td>0.689618</td>\n",
       "      <td>0.266591</td>\n",
       "      <td>0.283246</td>\n",
       "      <td>0.268389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>-0.282351</td>\n",
       "      <td>0.271146</td>\n",
       "      <td>-0.286560</td>\n",
       "      <td>0.225149</td>\n",
       "      <td>-0.333289</td>\n",
       "      <td>0.256966</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>-0.012330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  xgb_oct_under  xgb_oct_over  xgb_nov_under  xgb_nov_over  \\\n",
       "0  10754147      -0.198943      0.087975      -0.209733      0.085679   \n",
       "1  10759547      -0.110940      0.081205      -0.114238      0.079867   \n",
       "2  10843547      -0.269981      0.624938      -0.287432      0.675193   \n",
       "3  10859147      -0.224659      0.487692      -0.223898      0.511500   \n",
       "4  10879947      -0.282351      0.271146      -0.286560      0.225149   \n",
       "\n",
       "   xgb_dec_under  xgb_dec_over  overestimate_prob   xgb_oct   xgb_nov  \\\n",
       "0      -0.193651      0.087517           0.509328 -0.052808 -0.059271   \n",
       "1      -0.110725      0.081849           0.507312 -0.013462 -0.015767   \n",
       "2      -0.259808      0.618806           1.000000  0.624938  0.675193   \n",
       "3      -0.199660      0.479048           0.689618  0.266591  0.283246   \n",
       "4      -0.333289      0.256966           0.543763  0.018620 -0.008311   \n",
       "\n",
       "    xgb_dec  \n",
       "0 -0.050444  \n",
       "1 -0.013030  \n",
       "2  0.618806  \n",
       "3  0.268389  \n",
       "4 -0.012330  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_submission = DataFrame({'ParcelId': test_predictions['parcelid'],\n",
    "                           '201610':test_predictions['xgb_oct'],\n",
    "                           '201611':test_predictions['xgb_nov'],\n",
    "                           '201612':test_predictions['xgb_dec']})\n",
    "new_submission['201710'] = 0\n",
    "new_submission['201711'] = 0\n",
    "new_submission['201712'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06357010247136825,\n",
       " 0.062275520262869734,\n",
       " 0.07545290396779751,\n",
       " 0.065712491219854813)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two-stage with rf\n",
    "mean_absolute_errors(new_submission.round(4), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06211727600763514,\n",
       " 0.06136520946002188,\n",
       " 0.07414289916043706,\n",
       " 0.064404712807773379)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous RF\n",
    "RF = pd.read_csv(\"/home/anerdi/Desktop/Zillow/submissions/XGB_600.gz\", compression=\"gzip\")\n",
    "mean_absolute_errors(RF, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_submission.round(4).to_csv(\"/home/anerdi/Desktop/Zillow/submissions/two_stage_xgb.csv.gz\", index=False,\n",
    "                     compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
