{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import feature_pipelines as pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_regression_preds(reg,test_df, model_name='pred_logerror', transactiondate='2016-12-01'):\n",
    "    test_df['transactiondate'] = pd.Timestamp(transactiondate)  # Dummy\n",
    "    test_df = add_date_features(test_df)\n",
    "    reg_preds = None\n",
    "    for i in range(int(test_df.shape[0] / 100000)):   \n",
    "        # get current test features\n",
    "        current_test_feats = feature_pipeline.transform(test_df.iloc[i*100000:(i+1)*100000])\n",
    "\n",
    "        # predict on current test obs\n",
    "        current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                              index = np.arange(i*100000,(i+1)*100000))\n",
    "\n",
    "        if reg_preds is not None:\n",
    "            reg_preds = pd.concat([reg_preds, current_preds])\n",
    "        else:\n",
    "            reg_preds = current_preds\n",
    "\n",
    "    #  fencepost problem\n",
    "    current_test_feats = feature_pipeline.transform(test_df.iloc[2900000:])\n",
    "    current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                          index = np.arange(2900000,2985217))\n",
    "    reg_preds = pd.concat([reg_preds, current_preds])\n",
    "    return reg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submissions(oct_model,nov_model,dec_model,name='new_submission',logy=True):\n",
    "    \"\"\"\n",
    "    This function creates the submission file for the public leaderboard predictions.\n",
    "    Three already fitted models, one for each of the predicting time points, is required.\n",
    "    \"\"\"\n",
    "    submission_df = DataFrame()\n",
    "    for i in range(int(properties.shape[0] / 100000)):\n",
    "        all_feats = full_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "        foo = properties.iloc[i*100000:(i+1)*100000][['parcelid']].reset_index(drop=True)\n",
    "        if logy:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                            '201611': nov_model.predict(all_feats),\n",
    "                                                            '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "        else:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': np.log(oct_model.predict(all_feats)),\n",
    "                                                            '201611': np.log(nov_model.predict(all_feats)),\n",
    "                                                            '201612': np.log(dec_model.predict(all_feats))})], axis=1)\n",
    "        submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "    #  fencepost problem\n",
    "    all_feats = full_pipeline.transform(properties.iloc[2900000:])\n",
    "    foo = properties.iloc[2900000:][['parcelid']].reset_index(drop=True)\n",
    "    foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                    '201611': nov_model.predict(all_feats),\n",
    "                                                    '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "    submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "    submission_df['201710'] = 0\n",
    "    submission_df['201711'] = 0\n",
    "    submission_df['201712'] = 0\n",
    "    \n",
    "    submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "#     submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "#                                                                                            '201710','201711','201712']].round(4)\n",
    "    # unit test\n",
    "    submission_df.drop_duplicates(inplace=True)\n",
    "    assert submission_df.shape[0] == properties.shape[0]\n",
    "    # write to .csv\n",
    "    submission_df[['ParcelId','201610','201611','201612',\n",
    "                  '201710','201711','201712']].to_csv(name + \".gz\", index=False, float_format='%.4g', compression='gzip')\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "\n",
    "# train_df = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\", parse_dates=['transactiondate'], low_memory=False)\n",
    "train_df = pd.read_csv(\"/home/anerdi/Desktop/Zillow/data/traindata20162017.csv.gz\", parse_dates=['transactiondate'], low_memory=False)\n",
    "test_df = pd.read_csv(maindir + \"/data/sample_submission.csv\", low_memory=False)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\", low_memory=False)\n",
    "# field is named differently in submission\n",
    "test_df['parcelid'] = test_df['ParcelId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar to the1owl\n",
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (167888, 66)\n",
      "Test:  (2985217, 65)\n"
     ]
    }
   ],
   "source": [
    "train_df = add_date_features(train_df)\n",
    "# train_df = train_df.merge(properties, how='left', on='parcelid')\n",
    "test_df = test_df.merge(properties, how='left', on='parcelid')\n",
    "print(\"Train: \", train_df.shape)\n",
    "print(\"Test: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in ['propertycountylandusecode']:\n",
    "    label_enc = LabelEncoder()\n",
    "    test_df[c] = label_enc.fit_transform(test_df[c].astype(str))\n",
    "    train_df[c] = label_enc.transform(train_df[c].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some out of range int is a good choice\n",
    "train_df.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)\n",
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01')  # Dummy\n",
    "test_df = add_date_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data  Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# train_feats = ['airconditioningtypeid', 'bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr',\n",
    "#                'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12',\n",
    "#                'finishedsquarefeet15', 'finishedsquarefeet50', 'fips', 'fireplacecnt', 'fullbathcnt', \n",
    "#                'garagecarcnt', 'garagetotalsqft', 'heatingorsystemtypeid', 'latitude', 'longitude', \n",
    "#                'lotsizesquarefeet', 'propertycountylandusecode', 'propertylandusetypeid', 'rawcensustractandblock',\n",
    "#                'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', \n",
    "#                'threequarterbathnbr', 'unitcnt', 'yardbuildingsqft17', 'yearbuilt', 'numberofstories', \n",
    "#                'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'assessmentyear', 'landtaxvaluedollarcnt', \n",
    "#                'taxamount', 'taxdelinquencyyear', 'censustractandblock', 'transaction_year', 'transaction_month', \n",
    "#                'transaction_day', 'transaction_quarter']\n",
    "\n",
    "# # categorical varaibles\n",
    "# cat_atts = ['airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', \n",
    "#             'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty',\n",
    "#             'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear', 'taxdelinquencyyear', \n",
    "#             'transaction_year', 'transaction_month', 'transaction_day', 'transaction_quarter']\n",
    "\n",
    "train_feats = ['bedroomcnt','calculatedbathnbr',\n",
    "           'calculatedfinishedsquarefeet','fullbathcnt','garagecarcnt','garagetotalsqft',\n",
    "            'latitude','longitude','lotsizesquarefeet', 'roomcnt',\n",
    "           'numberofstories','structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount',   \n",
    "               'propertycountylandusecode', \n",
    "               'propertylandusetypeid',\n",
    "               'regionidzip',  \n",
    "               'yearbuilt', \n",
    "               'transaction_year', \n",
    "               'transaction_month'\n",
    "              ]\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = [\n",
    "               'propertylandusetypeid',\n",
    "               'regionidzip',  \n",
    "               'yearbuilt', \n",
    "               'transaction_year', \n",
    "               'transaction_month'\n",
    "              ]\n",
    "\n",
    "# numerical variables\n",
    "num_atts = [c for c in train_feats if c not in cat_atts]\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {c:np.union1d(test_df[c].unique(), train_df[c].unique()) for c in cat_atts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', pipes.DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', pipes.DataFrameSelector(num_atts)),\n",
    "#         ('imputer', Imputer()),\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['bedroomcnt', 'calculatedbathnbr', 'calculatedfinishedsquarefeet', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'latitude', 'longitude', 'lotsizesquarefeet', 'roomcnt', 'numberofsto...countylandusecode': array([  0,   1, ..., 239, 240]), 'transaction_year': array([2016, 2017])}))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(test_df) #fitting the pipeline to the entire properties dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167888, 857) (167888,)\n"
     ]
    }
   ],
   "source": [
    "X_train = feature_pipeline.transform(train_df)\n",
    "y_train = train_df.logerror\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {}\n",
    "xgb_params['n_estimators'] = 200\n",
    "xgb_params['learning_rate'] = 0.05\n",
    "xgb_params['max_depth'] = 3\n",
    "# xgb_params['subsample'] = 0.6\n",
    "xgb_params['reg_lambda'] = 1.5\n",
    "# xgb_params['reg_alpha'] = 0.8\n",
    "# xgb_params['colsample_bytree'] = 0.7\n",
    "xgb_params['silent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"xgb\",XGBRegressor(**xgb_params))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: xgb\n",
      "1\n",
      "...fitting model\n",
      "...obtaining predictions on test set\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\", usecols=['parcelid'])\n",
    "\n",
    "for pair in models:\n",
    "    current_model_name,current_model = pair\n",
    "    print(\"Current model: %s\" % current_model_name)\n",
    "    \n",
    "    num_ensembles = 5\n",
    "    y_pred_oct = Series(np.zeros(2985217), name = \"{0}_201610\".format(current_model_name))\n",
    "    y_pred_nov = Series(np.zeros(2985217), name = \"{0}_201611\".format(current_model_name))\n",
    "    y_pred_dec = Series(np.zeros(2985217), name = \"{0}_201612\".format(current_model_name))\n",
    "    for i in range(num_ensembles):            \n",
    "        # get a clone of the model and fit the current training data\n",
    "        print(i+1)\n",
    "        reg = clone(current_model)\n",
    "        reg.set_params(random_state=i)\n",
    "        \n",
    "        print(\"...fitting model\")\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        print(\"...obtaining predictions on test set\")\n",
    "        # obtain predictions on test set  \n",
    "        y_pred_oct = y_pred_oct + generate_regression_preds(reg, test_df, model_name=\"{0}_201610\".format(current_model_name),\n",
    "                                                            transactiondate='2016-10-01')\n",
    "        y_pred_nov = y_pred_nov + generate_regression_preds(reg, test_df, model_name=\"{0}_201611\".format(current_model_name), \n",
    "                                                            transactiondate='2016-11-01')\n",
    "        y_pred_dec = y_pred_dec + generate_regression_preds(reg, test_df, model_name=\"{0}_201612\".format(current_model_name),\n",
    "                                                            transactiondate='2016-12-01')\n",
    "        \n",
    "        del reg\n",
    "        gc.collect()\n",
    "\n",
    "    # model averaging    \n",
    "    y_pred_oct = y_pred_oct / num_ensembles\n",
    "    y_pred_nov = y_pred_nov / num_ensembles\n",
    "    y_pred_dec = y_pred_dec / num_ensembles\n",
    "    test_predictions = pd.concat([test_predictions, y_pred_oct, y_pred_nov, y_pred_dec], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'xgb'\n",
    "new_submission_one_stage = DataFrame({'ParcelId': test_predictions['parcelid'],\n",
    "                           '201610':test_predictions['%s_201610' % model_name],\n",
    "                           '201611':test_predictions['%s_201611' % model_name],\n",
    "                           '201612':test_predictions['%s_201612' % model_name],\n",
    "})\n",
    "new_submission_one_stage['201710'] = 0\n",
    "new_submission_one_stage['201711'] = 0\n",
    "new_submission_one_stage['201712'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_errors(new_submission_one_stage.round(4), train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
