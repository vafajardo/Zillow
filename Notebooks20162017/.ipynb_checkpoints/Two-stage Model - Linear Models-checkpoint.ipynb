{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from scipy.stats import mode,rankdata\n",
    "\n",
    "import feature_pipelines as pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_regression_preds(reg, properties, model_name='pred_logerror', trx_date = '2016-12-01'):\n",
    "    reg_preds = None\n",
    "    # change month of properties\n",
    "#     properties['month'] = month\n",
    "#     properties['year'] = 2016\n",
    "    properties['transactiondate'] = pd.Timestamp(trx_date)\n",
    "    properties = add_date_features(properties)\n",
    "    for i in range(int(properties.shape[0] / 100000)):   \n",
    "        # get current test features\n",
    "        current_test_feats = feature_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "\n",
    "        # predict on current test obs\n",
    "        current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                              index = np.arange(i*100000,(i+1)*100000))\n",
    "\n",
    "        if reg_preds is not None:\n",
    "            reg_preds = pd.concat([reg_preds, current_preds])\n",
    "        else:\n",
    "            reg_preds = current_preds\n",
    "\n",
    "    #  fencepost problem\n",
    "    current_test_feats = feature_pipeline.transform(properties.iloc[2900000:])\n",
    "    current_preds = Series(reg.predict(current_test_feats), name=model_name,\n",
    "                          index = np.arange(2900000,2985217))\n",
    "    reg_preds = pd.concat([reg_preds, current_preds])\n",
    "    \n",
    "    del properties['month']\n",
    "    return reg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submissions(oct_model,nov_model,dec_model,name='new_submission',logy=True):\n",
    "    \"\"\"\n",
    "    This function creates the submission file for the public leaderboard predictions.\n",
    "    Three already fitted models, one for each of the predicting time points, is required.\n",
    "    \"\"\"\n",
    "    submission_df = DataFrame()\n",
    "    for i in range(int(properties.shape[0] / 100000)):\n",
    "        all_feats = full_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "        foo = properties.iloc[i*100000:(i+1)*100000][['parcelid']].reset_index(drop=True)\n",
    "        if logy:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                            '201611': nov_model.predict(all_feats),\n",
    "                                                            '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "        else:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': np.log(oct_model.predict(all_feats)),\n",
    "                                                            '201611': np.log(nov_model.predict(all_feats)),\n",
    "                                                            '201612': np.log(dec_model.predict(all_feats))})], axis=1)\n",
    "        submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "    #  fencepost problem\n",
    "    all_feats = full_pipeline.transform(properties.iloc[2900000:])\n",
    "    foo = properties.iloc[2900000:][['parcelid']].reset_index(drop=True)\n",
    "    foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                    '201611': nov_model.predict(all_feats),\n",
    "                                                    '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "    submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "    submission_df['201710'] = 0\n",
    "    submission_df['201711'] = 0\n",
    "    submission_df['201712'] = 0\n",
    "    \n",
    "    submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "#     submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "#                                                                                            '201710','201711','201712']].round(4)\n",
    "    # unit test\n",
    "    submission_df.drop_duplicates(inplace=True)\n",
    "    assert submission_df.shape[0] == properties.shape[0]\n",
    "    # write to .csv\n",
    "    submission_df[['ParcelId','201610','201611','201612',\n",
    "                  '201710','201711','201712']].to_csv(name + \".gz\", index=False, float_format='%.4g', compression='gzip')\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar to the1owl\n",
    "def add_date_features(df):\n",
    "    df[\"year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"month\"] = df[\"transactiondate\"].dt.month\n",
    "    df[\"day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"quarter\"] = df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/anerdi/Desktop/Zillow/data/traindata20162017_addfeatures.csv.gz\", compression='gzip',\n",
    "                  parse_dates=['transactiondate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = add_date_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data  Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['garagetotalsqft', \n",
    "            'calculatedbathnbr',\n",
    "            'structuretaxvaluedollarcnt',\n",
    "            'bedroomcnt',\n",
    "            'age']\n",
    "\n",
    "num_atts_to_interact = ['calculatedfinishedsquarefeet', 'lotsizesquarefeet']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid',\n",
    "            'heatingorsystemtypeid',\n",
    "            'Pool',\n",
    "            'propertylandusetypeid',\n",
    "            'taxdelinquencyflag',\n",
    "            'architecturalstyletypeid',\n",
    "            'regionidcounty',\n",
    "            'month',\n",
    "           'year']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {key:value for key,value in {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'Pool': [0,1],\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [-1]+ [2061,3101,1286],\n",
    "            'month': [-1] + list(range(1,13)),\n",
    "            'year': [2016,2017],\n",
    "            'quarter': [1,2,3,4],\n",
    "            'zestimate_type': [1,2,3],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }.items() if key in cat_atts}\n",
    "\n",
    "# pairs to interact (x1,x2) where x1 is categorical and x2 is continuous\n",
    "interact_pairs = [\n",
    "                ('regionidcounty','calculatedbathnbr'),\n",
    "                ('regionidcounty','bedroomcnt'),\n",
    "                ('regionidcounty','structuretaxvaluedollarcnt'),\n",
    "                ('regionidcounty','age'),\n",
    "                ('year','calculatedfinishedsquarefeet'),\n",
    "                ('year','structuretaxvaluedollarcnt')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', pipes.DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', pipes.DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# interaction pipelines\n",
    "cat_interact_pipeline = Pipeline([\n",
    "        ('dummify_and_interact',pipes.Dummify_and_Interact(interact_pairs,cat_dict)),\n",
    "    ])\n",
    "\n",
    "num_interact_pipeline = Pipeline([\n",
    "        ('selector', pipes.DataFrameSelector(num_atts_to_interact)),\n",
    "        ('imputer', Imputer()),\n",
    "        ('polynomial_features', PolynomialFeatures(2, include_bias=False)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"num_interact_pipeline\", num_interact_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "        (\"cat_interact_pipeline\", cat_interact_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['garagetotalsqft', 'calculatedbathnbr', 'structuretaxvaluedollarcnt', 'bedroomcnt', 'age'])), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), (...ty', 'age'), ('year', 'calculatedfinishedsquarefeet'), ('year', 'structuretaxvaluedollarcnt')]))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(data) #fitting the pipeline to the entire properties dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "# properties = pd.read_csv(maindir + \"/data/properties_2016_with_2017_tax.csv\")\n",
    "\n",
    "# #proportion of living area\n",
    "# properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "\n",
    "# properties['N-NonLivingAreaProp'] = properties['garagetotalsqft']/properties['lotsizesquarefeet']\n",
    "\n",
    "# #Ratio of the built structure value to land area\n",
    "# properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "# #Ratio of tax of property over parcel\n",
    "# properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']\n",
    "\n",
    "# # Pool\n",
    "# properties['poolsizesum'] = properties['poolsizesum'].fillna(0)\n",
    "# # properties['Pool'] = (properties['poolsizesum'] > 0).astype(int)\n",
    "# properties['Pool'] = (properties['pooltypeid2'].fillna(0) + properties['pooltypeid7'].fillna(0)).astype(int)\n",
    "\n",
    "# properties['regionidcounty'] = properties['regionidcounty'].fillna(9999)\n",
    "# properties['regionidcity'] = properties['regionidcity'].fillna(9999)\n",
    "# properties['regionidneighborhood'] = properties['regionidneighborhood'].fillna(9999)\n",
    "# properties['regionidzip'] = properties['regionidzip'].fillna(9999)\n",
    "# properties['typeconstructiontypeid'] = properties['typeconstructiontypeid'].fillna(9999)\n",
    "# properties['airconditioningtypeid'] = properties['airconditioningtypeid'].fillna(9999)\n",
    "# properties['buildingqualitytypeid'] = properties['buildingqualitytypeid'].fillna(9999)\n",
    "# properties['heatingorsystemtypeid'] = properties['heatingorsystemtypeid'].fillna(9999)\n",
    "# properties['propertylandusetypeid'] = properties['propertylandusetypeid'].fillna(9999)\n",
    "# properties['fips'] = properties['fips'].fillna(9999)\n",
    "\n",
    "# # some more feature engineering\n",
    "# properties['age'] = 2017 - properties['yearbuilt']\n",
    "# properties['additional_rooms_count'] = np.maximum((properties['roomcnt'].values \n",
    "#                                                    - properties['calculatedbathnbr'].values\n",
    "#                                                    - properties['bedroomcnt'].values),0)\n",
    "\n",
    "# # impute missing num_atts per regionid\n",
    "# for countyid in properties.regionidcounty.unique():\n",
    "#     # setup condition\n",
    "#     cond = properties['regionidcounty'] == countyid\n",
    "#     indices = np.where(cond)[0]\n",
    "#     # impute values based on region\n",
    "#     if countyid != 9999:\n",
    "#         properties.loc[indices,num_atts] = (properties.loc[indices,num_atts]\n",
    "#                                 .fillna(properties.loc[indices,num_atts]\n",
    "#                                 .apply(np.mean)))\n",
    "#     else:\n",
    "#         properties.loc[indices,num_atts] = (properties.loc[indices,num_atts]\n",
    "#                                             .fillna(properties[num_atts]\n",
    "#                                             .apply(np.mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "properties.drop([c for c in properties.columns if c not in num_atts + num_atts_to_interact + cat_atts + ['parcelid']],\n",
    "               axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_overestimated = np.where(data['logerror'] >= 0)[0]\n",
    "ix_underestimated = np.where(data['logerror'] < 0)[0]\n",
    "data_indices = {\"over\": ix_overestimated, \"under\": ix_underestimated}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert ix_overestimated.shape[0] + ix_underestimated.shape[0] == data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lars, HuberRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"ridge\",ElasticNet(alpha=1.25, l1_ratio = 0, max_iter=1000)),\n",
    "#     (\"ridge2\",ElasticNet(alpha=10, l1_ratio = 0, max_iter=1000)),\n",
    "#     (\"ridge3\",ElasticNet(alpha=15, l1_ratio = 0, max_iter=1000)),\n",
    "#     (\"enet\", ElasticNet(alpha=0.025, l1_ratio = 0.5, max_iter=1000)),\n",
    "#     (\"lasso\", ElasticNet(alpha=0.025, l1_ratio = 1, max_iter=1000)),\n",
    "#     (\"larm\", Lars(n_nonzero_coefs = 1)),\n",
    "#     (\"huber\", HuberRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: ridge\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pd.read_csv(maindir + \"/data/properties_2016_with_2017_tax.csv\", usecols=['parcelid'])\n",
    "\n",
    "for pair in models:\n",
    "    current_model_name,current_model = pair\n",
    "    print(\"Current model: %s\" % current_model_name)\n",
    "    \n",
    "    for key,val in data_indices.items():\n",
    "        type_of_zestimate, ix = key, val\n",
    "\n",
    "        # preprocess current training data\n",
    "        current_traindata = data.iloc[ix,]\n",
    "\n",
    "        # get a clone of the model and fit the current training data\n",
    "        reg = clone(current_model)\n",
    "        reg.fit(feature_pipeline.transform(current_traindata), current_traindata['logerror'])\n",
    "\n",
    "#         for month in [10,11,12]:\n",
    "        for trx_date in ['2016-10-01','2016-11-01','2016-12-01']:\n",
    "            # obtain predictions on test set\n",
    "            dateobj = datetime.datetime.strptime(trx_date,'%Y-%m-%d')\n",
    "            reg_preds = generate_regression_preds(reg, properties,\n",
    "                  model_name=\"%s_%d_%s\" % (current_model_name,dateobj.month,type_of_zestimate), trx_date=trx_date)\n",
    "            test_predictions = pd.concat([test_predictions, reg_preds], axis=1)\n",
    "        \n",
    "        del reg\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ridge_10_under</th>\n",
       "      <th>ridge_11_under</th>\n",
       "      <th>ridge_12_under</th>\n",
       "      <th>ridge_10_over</th>\n",
       "      <th>ridge_11_over</th>\n",
       "      <th>ridge_12_over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.080649</td>\n",
       "      <td>-0.080694</td>\n",
       "      <td>-0.080743</td>\n",
       "      <td>0.080019</td>\n",
       "      <td>0.080037</td>\n",
       "      <td>0.080164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.078461</td>\n",
       "      <td>-0.078506</td>\n",
       "      <td>-0.078556</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.078145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>-1.192476</td>\n",
       "      <td>-1.192521</td>\n",
       "      <td>-1.192571</td>\n",
       "      <td>1.802936</td>\n",
       "      <td>1.802954</td>\n",
       "      <td>1.803081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>-0.115702</td>\n",
       "      <td>-0.115751</td>\n",
       "      <td>0.111204</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.111348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>-0.091642</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.091737</td>\n",
       "      <td>0.089616</td>\n",
       "      <td>0.089634</td>\n",
       "      <td>0.089760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  ridge_10_under  ridge_11_under  ridge_12_under  ridge_10_over  \\\n",
       "0  10754147       -0.080649       -0.080694       -0.080743       0.080019   \n",
       "1  10759547       -0.078461       -0.078506       -0.078556       0.078000   \n",
       "2  10843547       -1.192476       -1.192521       -1.192571       1.802936   \n",
       "3  10859147       -0.115657       -0.115702       -0.115751       0.111204   \n",
       "4  10879947       -0.091642       -0.091688       -0.091737       0.089616   \n",
       "\n",
       "   ridge_11_over  ridge_12_over  \n",
       "0       0.080037       0.080164  \n",
       "1       0.078018       0.078145  \n",
       "2       1.802954       1.803081  \n",
       "3       0.111222       0.111348  \n",
       "4       0.089634       0.089760  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_predictions.to_csv(\"/home/anerdi/Desktop/Zillow/twostagemodel/two_stage_preds_linear_models_201617.csv.gz\",\n",
    "#                        compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overestimate_probabilities = pd.read_csv(\"/home/anerdi/Desktop/Zillow/twostagemodel/overestimate_probs_stacked_ann_rfs_xgbs_lgbms_20162017.csv.gz\")\n",
    "overestimate_probabilities.rename(columns={'stacked_pred':'overestimate_prob'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ann_overestimate_prob</th>\n",
       "      <th>rf2_overestimate_prob</th>\n",
       "      <th>rf3_overestimate_prob</th>\n",
       "      <th>xgb1_overestimate_prob</th>\n",
       "      <th>xgb2_overestimate_prob</th>\n",
       "      <th>lgbm1_overestimate_prob</th>\n",
       "      <th>lgbm2_overestimate_prob</th>\n",
       "      <th>overestimate_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.497368</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>0.479722</td>\n",
       "      <td>0.511108</td>\n",
       "      <td>0.650032</td>\n",
       "      <td>0.515646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0.412405</td>\n",
       "      <td>0.500739</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.525333</td>\n",
       "      <td>0.527149</td>\n",
       "      <td>0.543325</td>\n",
       "      <td>0.646905</td>\n",
       "      <td>0.553857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.527465</td>\n",
       "      <td>0.636537</td>\n",
       "      <td>0.535855</td>\n",
       "      <td>0.411728</td>\n",
       "      <td>0.522140</td>\n",
       "      <td>0.544722</td>\n",
       "      <td>0.501281</td>\n",
       "      <td>0.466540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.665014</td>\n",
       "      <td>0.648656</td>\n",
       "      <td>0.456073</td>\n",
       "      <td>0.580416</td>\n",
       "      <td>0.570832</td>\n",
       "      <td>0.590595</td>\n",
       "      <td>0.576605</td>\n",
       "      <td>0.581211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.477125</td>\n",
       "      <td>0.524182</td>\n",
       "      <td>0.483156</td>\n",
       "      <td>0.514524</td>\n",
       "      <td>0.509930</td>\n",
       "      <td>0.515008</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.483875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  ann_overestimate_prob  rf2_overestimate_prob  \\\n",
       "0  10754147               0.466125               0.497368   \n",
       "1  10759547               0.412405               0.500739   \n",
       "2  10843547               0.527465               0.636537   \n",
       "3  10859147               0.665014               0.648656   \n",
       "4  10879947               0.477125               0.524182   \n",
       "\n",
       "   rf3_overestimate_prob  xgb1_overestimate_prob  xgb2_overestimate_prob  \\\n",
       "0               0.560124                0.462231                0.479722   \n",
       "1               0.420662                0.525333                0.527149   \n",
       "2               0.535855                0.411728                0.522140   \n",
       "3               0.456073                0.580416                0.570832   \n",
       "4               0.483156                0.514524                0.509930   \n",
       "\n",
       "   lgbm1_overestimate_prob  lgbm2_overestimate_prob  overestimate_prob  \n",
       "0                 0.511108                 0.650032           0.515646  \n",
       "1                 0.543325                 0.646905           0.553857  \n",
       "2                 0.544722                 0.501281           0.466540  \n",
       "3                 0.590595                 0.576605           0.581211  \n",
       "4                 0.515008                 0.404796           0.483875  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overestimate_probabilities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = pd.merge(test_predictions, overestimate_probabilities, on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pair in models:\n",
    "    current_model_name, current_model = pair\n",
    "    # combine over and under to get prediction\n",
    "    for month in [10,11,12]:\n",
    "        test_predictions['%s_%d' % (current_model_name, month)] = (\n",
    "                test_predictions['%s_%d_over' % (current_model_name, month)]*test_predictions['overestimate_prob'] \n",
    "                + test_predictions['%s_%d_under' % (current_model_name, month)]*(1 - test_predictions['overestimate_prob']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ridge_10_under</th>\n",
       "      <th>ridge_11_under</th>\n",
       "      <th>ridge_12_under</th>\n",
       "      <th>ridge_10_over</th>\n",
       "      <th>ridge_11_over</th>\n",
       "      <th>ridge_12_over</th>\n",
       "      <th>ann_overestimate_prob</th>\n",
       "      <th>rf2_overestimate_prob</th>\n",
       "      <th>rf3_overestimate_prob</th>\n",
       "      <th>xgb1_overestimate_prob</th>\n",
       "      <th>xgb2_overestimate_prob</th>\n",
       "      <th>lgbm1_overestimate_prob</th>\n",
       "      <th>lgbm2_overestimate_prob</th>\n",
       "      <th>overestimate_prob</th>\n",
       "      <th>ridge_10</th>\n",
       "      <th>ridge_11</th>\n",
       "      <th>ridge_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.080649</td>\n",
       "      <td>-0.080694</td>\n",
       "      <td>-0.080743</td>\n",
       "      <td>0.080019</td>\n",
       "      <td>0.080037</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.497368</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>0.479722</td>\n",
       "      <td>0.511108</td>\n",
       "      <td>0.650032</td>\n",
       "      <td>0.515646</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.078461</td>\n",
       "      <td>-0.078506</td>\n",
       "      <td>-0.078556</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.078145</td>\n",
       "      <td>0.412405</td>\n",
       "      <td>0.500739</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.525333</td>\n",
       "      <td>0.527149</td>\n",
       "      <td>0.543325</td>\n",
       "      <td>0.646905</td>\n",
       "      <td>0.553857</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.008234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>-1.192476</td>\n",
       "      <td>-1.192521</td>\n",
       "      <td>-1.192571</td>\n",
       "      <td>1.802936</td>\n",
       "      <td>1.802954</td>\n",
       "      <td>1.803081</td>\n",
       "      <td>0.527465</td>\n",
       "      <td>0.636537</td>\n",
       "      <td>0.535855</td>\n",
       "      <td>0.411728</td>\n",
       "      <td>0.522140</td>\n",
       "      <td>0.544722</td>\n",
       "      <td>0.501281</td>\n",
       "      <td>0.466540</td>\n",
       "      <td>0.205003</td>\n",
       "      <td>0.204987</td>\n",
       "      <td>0.205020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>-0.115702</td>\n",
       "      <td>-0.115751</td>\n",
       "      <td>0.111204</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>0.665014</td>\n",
       "      <td>0.648656</td>\n",
       "      <td>0.456073</td>\n",
       "      <td>0.580416</td>\n",
       "      <td>0.570832</td>\n",
       "      <td>0.590595</td>\n",
       "      <td>0.576605</td>\n",
       "      <td>0.581211</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.016242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>-0.091642</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.091737</td>\n",
       "      <td>0.089616</td>\n",
       "      <td>0.089634</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.477125</td>\n",
       "      <td>0.524182</td>\n",
       "      <td>0.483156</td>\n",
       "      <td>0.514524</td>\n",
       "      <td>0.509930</td>\n",
       "      <td>0.515008</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.483875</td>\n",
       "      <td>-0.003936</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.003915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  ridge_10_under  ridge_11_under  ridge_12_under  ridge_10_over  \\\n",
       "0  10754147       -0.080649       -0.080694       -0.080743       0.080019   \n",
       "1  10759547       -0.078461       -0.078506       -0.078556       0.078000   \n",
       "2  10843547       -1.192476       -1.192521       -1.192571       1.802936   \n",
       "3  10859147       -0.115657       -0.115702       -0.115751       0.111204   \n",
       "4  10879947       -0.091642       -0.091688       -0.091737       0.089616   \n",
       "\n",
       "   ridge_11_over  ridge_12_over  ann_overestimate_prob  rf2_overestimate_prob  \\\n",
       "0       0.080037       0.080164               0.466125               0.497368   \n",
       "1       0.078018       0.078145               0.412405               0.500739   \n",
       "2       1.802954       1.803081               0.527465               0.636537   \n",
       "3       0.111222       0.111348               0.665014               0.648656   \n",
       "4       0.089634       0.089760               0.477125               0.524182   \n",
       "\n",
       "   rf3_overestimate_prob  xgb1_overestimate_prob  xgb2_overestimate_prob  \\\n",
       "0               0.560124                0.462231                0.479722   \n",
       "1               0.420662                0.525333                0.527149   \n",
       "2               0.535855                0.411728                0.522140   \n",
       "3               0.456073                0.580416                0.570832   \n",
       "4               0.483156                0.514524                0.509930   \n",
       "\n",
       "   lgbm1_overestimate_prob  lgbm2_overestimate_prob  overestimate_prob  \\\n",
       "0                 0.511108                 0.650032           0.515646   \n",
       "1                 0.543325                 0.646905           0.553857   \n",
       "2                 0.544722                 0.501281           0.466540   \n",
       "3                 0.590595                 0.576605           0.581211   \n",
       "4                 0.515008                 0.404796           0.483875   \n",
       "\n",
       "   ridge_10  ridge_11  ridge_12  \n",
       "0  0.002199  0.002186  0.002228  \n",
       "1  0.008196  0.008186  0.008234  \n",
       "2  0.205003  0.204987  0.205020  \n",
       "3  0.016197  0.016189  0.016242  \n",
       "4 -0.003936 -0.003951 -0.003915  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'ridge' # can be any one of ridge, enet, lasso, huber, or larm\n",
    "new_submission = DataFrame({'ParcelId': test_predictions['parcelid'],\n",
    "                           '201610':test_predictions['%s_10' % model_name],\n",
    "                           '201611':test_predictions['%s_11' % model_name],\n",
    "                           '201612':test_predictions['%s_12' % model_name],\n",
    "})\n",
    "new_submission['201710'] = 0\n",
    "new_submission['201711'] = 0\n",
    "new_submission['201712'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>10754147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>10759547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205003</td>\n",
       "      <td>0.204987</td>\n",
       "      <td>0.205020</td>\n",
       "      <td>10843547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>10859147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003936</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.003915</td>\n",
       "      <td>10879947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     201610    201611    201612  ParcelId  201710  201711  201712\n",
       "0  0.002199  0.002186  0.002228  10754147       0       0       0\n",
       "1  0.008196  0.008186  0.008234  10759547       0       0       0\n",
       "2  0.205003  0.204987  0.205020  10843547       0       0       0\n",
       "3  0.016197  0.016189  0.016242  10859147       0       0       0\n",
       "4 -0.003936 -0.003951 -0.003915  10879947       0       0       0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06179845288326326,\n",
       " 0.060861117196056934,\n",
       " 0.0733271420356527,\n",
       " 0.063945118239288376)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha = 1.25\n",
    "mean_absolute_errors(new_submission.round(4), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06179774964838238,\n",
       " 0.06086330777656092,\n",
       " 0.07332208165612432,\n",
       " 0.063944146569889893)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha = 1.25\n",
    "mean_absolute_errors(new_submission.round(4), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_submission.round(4).to_csv(\"/home/anerdi/Desktop/Zillow/submissions/two_stage_stage1_annrfsxgbslgbms_stage2_ridge_201617_year.csv.gz\", index=False,\n",
    "                     compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
