{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#proportion of living area\n",
    "properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "\n",
    "#Ratio of the built structure value to land area\n",
    "properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "#Ratio of tax of property over parcel\n",
    "properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']\n",
    "\n",
    "# Pool\n",
    "properties['Pool'] = (properties['pooltypeid2'].fillna(0) + properties['pooltypeid7'].fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')\n",
    "data['wts_oct'] = np.where(data['month'] == 10, 1.5, 1)\n",
    "data['wts_nov'] = np.where(data['month'] == 11, 1.5, 1)\n",
    "data['wts_dec'] = np.where(data['month'] == 12, 1.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['calculatedfinishedsquarefeet','bathroomcnt','structuretaxvaluedollarcnt',\n",
    "             'bedroomcnt','calculatedbathnbr','roomcnt','longitude','threequarterbathnbr', 'yardbuildingsqft17',\n",
    "             'numberofstories','N-ValueRatio','N-ValueProp','N-LivingAreaProp']\n",
    "\n",
    "# num_atts = ['calculatedfinishedsquarefeet','bathroomcnt','structuretaxvaluedollarcnt',\n",
    "#              'bedroomcnt','calculatedbathnbr','N-ValueRatio','N-ValueProp','N-LivingAreaProp']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid','heatingorsystemtypeid','Pool','propertylandusetypeid','taxdelinquencyflag']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {key:value for key,value in {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'Pool': [0,1],\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [2061,3101,1286],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }.items() if key in cat_atts}\n",
    "\n",
    "# pairs to interact (x1,x2) where x1 is categorical and x2 is continuous\n",
    "interact_pairs = [('regionidcounty','bathroomcnt'),('regionidcounty','bedroomcnt')\n",
    "                 ,('regionidcounty','structuretaxvaluedollarcnt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom transformer, which selects certain variables\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, desired_cols):\n",
    "        self.desired_cols = desired_cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.desired_cols].values\n",
    "\n",
    "# A custom transformer, which first selects the categorical variables\n",
    "# from the DataFrame and then performs the dummification\n",
    "class DF_Selector_GetDummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_dict):\n",
    "        self.cat_dict = cat_dict\n",
    "        self.ndummies = sum(len(c) - 1  for c in cat_dict.values()) \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.fillna(-1) # missing values are given -1 missing label\n",
    "        foo = np.zeros((X.shape[0],self.ndummies))\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for c in sorted(self.cat_dict.keys()):\n",
    "            end += len(self.cat_dict[c]) - 1\n",
    "            foo[:, start:end] = pd.get_dummies(X[c].astype('category', categories=self.cat_dict[c]))[self.cat_dict[c][1:]]\n",
    "            start += len(self.cat_dict[c]) - 1\n",
    "        return foo\n",
    "\n",
    "class Dummify_and_Interact(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, interact_pairs, cat_dict):\n",
    "        self.interact_pairs = interact_pairs\n",
    "        self.cat_dict = cat_dict\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        features = None\n",
    "        for pair in self.interact_pairs:\n",
    "            x1,x2 = pair\n",
    "            # impute x2 if missing\n",
    "            imputer = Imputer()\n",
    "            if np.isnan(X[x2]).any():\n",
    "                x2vals = imputer.fit_transform(X[[x2]])\n",
    "            else:\n",
    "                x2vals = X[[x2]].as_matrix()\n",
    "            # dummify x1 and multiply by x2vals\n",
    "#             bar = ((pd.get_dummies(X[x1].astype('category', \n",
    "#                     categories=self.cat_dict[x1]))[self.cat_dict[x1][1:]]).as_matrix() * x2vals)\n",
    "            bar = pd.get_dummies(X[x1].astype('category'), drop_first=True)\n",
    "            if features is not None:\n",
    "                features = np.concatenate((features,bar),axis=1)\n",
    "            else:\n",
    "                features = bar\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "    ])\n",
    "\n",
    "# interaction pipeline\n",
    "interact_pipeline = Pipeline([\n",
    "        ('dummify_and_interact',Dummify_and_Interact(interact_pairs, cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "        (\"interact_pipeline\", interact_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into the 10-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24283, 53623, 10038, ..., 66037, 55934, 86364])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "np.random.shuffle(indices) # in-place shuffling \n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_indices = {(i+1):indices[i::10] for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([24283, 81578, 55185, ..., 88696, 19420, 22584]),\n",
       " 2: array([53623, 89226, 14417, ..., 80106, 39259, 65462]),\n",
       " 3: array([10038, 42930, 25710, ..., 25406, 50805, 66037]),\n",
       " 4: array([ 6560, 52504, 69020, ..., 44509, 61176, 55934]),\n",
       " 5: array([72110, 88930, 66005, ..., 46008, 10481, 86364]),\n",
       " 6: array([85819, 15175, 52495, ..., 36792, 36810, 62760]),\n",
       " 7: array([12329, 52468, 49812, ..., 18561, 36027, 88635]),\n",
       " 8: array([64150, 73168, 74499, ..., 69304, 24814, 70209]),\n",
       " 9: array([87434, 67401, 85581, ..., 71894, 82876,  5014]),\n",
       " 10: array([31642, 81045, 14458, ...,  6418, 81792, 42747])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models on the 10 splits of data \\ fold_i for i = 1,...,10 & obtaining level 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lars, HuberRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(memory=None,\n",
       "     steps=[('selector', DataFrameSelector(desired_cols=['calculatedfinishedsquarefeet', 'bathroomcnt', 'structuretaxvaluedollarcnt', 'bedroomcnt', 'calculatedbathnbr', 'roomcnt', 'longitude', 'threequarterbathnbr', 'yardbuildingsqft17', 'numb...roomcnt'), ('regionidcounty', 'bedroomcnt'), ('regionidcounty', 'structuretaxvaluedollarcnt')]))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline.fit(properties) #fitting the pipeline to the entire properties dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"ridge\",ElasticNet(alpha=1.25, l1_ratio = 0, max_iter=1000)),\n",
    "    (\"enet\", ElasticNet(alpha=1.25, l1_ratio = 0.5, max_iter=1000)),\n",
    "    (\"lasso\", ElasticNet(alpha=1.25, l1_ratio = 1, max_iter=1000)),\n",
    "    (\"larm\", Lars(n_nonzero_coefs = 1)),\n",
    "    (\"huber\", HuberRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: ridge\n",
      "...working on fold 1\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 2\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 3\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 4\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 5\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 6\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 7\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 8\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 9\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 10\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "\n",
      "Current model: enet\n",
      "...working on fold 1\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 2\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 3\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 4\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 5\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 6\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 7\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 8\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 9\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 10\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "\n",
      "Current model: lasso\n",
      "...working on fold 1\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 2\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 3\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 4\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 5\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 6\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 7\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 8\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 9\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 10\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "\n",
      "Current model: larm\n",
      "...working on fold 1\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 2\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 3\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 4\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 5\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 6\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 7\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 8\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 9\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 10\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "\n",
      "Current model: huber\n",
      "...working on fold 1\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 2\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 3\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 4\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 5\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 6\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 7\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 8\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 9\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "...working on fold 10\n",
      "......training model\n",
      "......obtaining level-one data\n",
      "\n",
      "all done!\n"
     ]
    }
   ],
   "source": [
    "level_one_data = data[['parcelid']].copy()\n",
    "\n",
    "for pair in models:\n",
    "    current_model_name,current_model = pair\n",
    "    print(\"Current model: %s\" % current_model_name)\n",
    "    \n",
    "    # initialize an NoneObject to be a placeholder for level-one data for current model\n",
    "    model_preds = None \n",
    "    \n",
    "    for fold_nbr in range(1,11):\n",
    "        print(\"...working on fold %d\" % fold_nbr)\n",
    "\n",
    "        # set training data X \\ fold\n",
    "        current_traindata = data.iloc[np.setdiff1d(indices,fold_indices[fold_nbr]),]\n",
    "\n",
    "        # get a clone of the model and fit the current training data\n",
    "        print('......training model')\n",
    "        reg = clone(current_model)\n",
    "        reg.fit(feature_pipeline.transform(current_traindata), current_traindata['logerror'])\n",
    "\n",
    "        # level-one data (i.e., predict observations on current fold using reg)\n",
    "        print('......obtaining level-one data')\n",
    "        fold_data = data.iloc[fold_indices[fold_nbr]]\n",
    "        fold_preds = Series(reg.predict(feature_pipeline.transform(fold_data)), \n",
    "                            index=fold_indices[fold_nbr], name = current_model_name)\n",
    "\n",
    "        # adding to the placeholder for level-one data\n",
    "        if model_preds is not None:\n",
    "            model_preds = pd.concat([model_preds, fold_preds])\n",
    "        else:\n",
    "            model_preds = fold_preds\n",
    "\n",
    "        # some housecleaning\n",
    "        del reg\n",
    "    \n",
    "    # add level-one predictions of current model to running dataframe\n",
    "    level_one_data = pd.concat([level_one_data, model_preds], axis=1)\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"all done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ridge</th>\n",
       "      <th>enet</th>\n",
       "      <th>lasso</th>\n",
       "      <th>larm</th>\n",
       "      <th>huber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17073783</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.011198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17088994</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.011144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17100444</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.010893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17102429</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.011408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17109604</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.011180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid     ridge      enet     lasso      larm     huber\n",
       "0  17073783  0.017901  0.010024  0.010388  0.010857  0.011198\n",
       "1  17088994  0.010651  0.006399  0.007616  0.009479  0.011144\n",
       "2  17100444  0.008782  0.008610  0.008853  0.010079  0.010893\n",
       "3  17102429  0.014618  0.012370  0.012010  0.011320  0.011408\n",
       "4  17109604  0.018050  0.016426  0.015855  0.012941  0.011180"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_one_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_one_data.to_csv(\"levelonedata/l1data_linear_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
