{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submissions(oct_model,nov_model,dec_model,name='new_submission',logy=True):\n",
    "    \"\"\"\n",
    "    This function creates the submission file for the public leaderboard predictions.\n",
    "    Three already fitted models, one for each of the predicting time points, is required.\n",
    "    \"\"\"\n",
    "    submission_df = DataFrame()\n",
    "    for i in range(int(properties.shape[0] / 100000)):\n",
    "        all_feats = full_pipeline.transform(properties.iloc[i*100000:(i+1)*100000])\n",
    "        foo = properties.iloc[i*100000:(i+1)*100000][['parcelid']].reset_index(drop=True)\n",
    "        if logy:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                            '201611': nov_model.predict(all_feats),\n",
    "                                                            '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "        else:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': np.log(oct_model.predict(all_feats)),\n",
    "                                                            '201611': np.log(nov_model.predict(all_feats)),\n",
    "                                                            '201612': np.log(dec_model.predict(all_feats))})], axis=1)\n",
    "        submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "    #  fencepost problem\n",
    "    all_feats = full_pipeline.transform(properties.iloc[2900000:])\n",
    "    foo = properties.iloc[2900000:][['parcelid']].reset_index(drop=True)\n",
    "    foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                    '201611': nov_model.predict(all_feats),\n",
    "                                                    '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "    submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "    submission_df['201710'] = 0\n",
    "    submission_df['201711'] = 0\n",
    "    submission_df['201712'] = 0\n",
    "    \n",
    "    submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "#     submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "#                                                                                            '201710','201711','201712']].round(4)\n",
    "    # unit test\n",
    "    submission_df.drop_duplicates(inplace=True)\n",
    "    assert submission_df.shape[0] == properties.shape[0]\n",
    "    # write to .csv\n",
    "    submission_df[['ParcelId','201610','201611','201612',\n",
    "                  '201710','201711','201712']].to_csv(name + \".gz\", index=False, float_format='%.4g', compression='gzip')\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\"\n",
    "\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")\n",
    "# test_parcels = pd.read_csv(maindir + \"/data/sample_submission.csv\", usecols = ['ParcelId'])\n",
    "# test_parcels.rename(columns={'ParcelId':'parcelid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#proportion of living area\n",
    "properties['N-LivingAreaProp'] = properties['calculatedfinishedsquarefeet']/properties['lotsizesquarefeet']\n",
    "\n",
    "#Ratio of the built structure value to land area\n",
    "properties['N-ValueProp'] = properties['structuretaxvaluedollarcnt']/properties['landtaxvaluedollarcnt']\n",
    "\n",
    "#Ratio of tax of property over parcel\n",
    "properties['N-ValueRatio'] = properties['taxvaluedollarcnt']/properties['taxamount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data  Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_atts = ['calculatedfinishedsquarefeet','bathroomcnt','structuretaxvaluedollarcnt',\n",
    "             'bedroomcnt','calculatedbathnbr','roomcnt','longitude','threequarterbathnbr', 'yardbuildingsqft17',\n",
    "             'numberofstories','N-ValueRatio','N-ValueProp','N-LivingAreaProp']\n",
    "\n",
    "# categorical varaibles\n",
    "cat_atts = ['airconditioningtypeid','heatingorsystemtypeid','pooltypeid10','pooltypeid2',\n",
    "            'pooltypeid7','propertylandusetypeid','taxdelinquencyflag']\n",
    "\n",
    "# Dictionary of categorical variables and their default levels\n",
    "cat_dict = {key:value for key,value in {'airconditioningtypeid':[-1] + list(range(1,14)),\n",
    "           'architecturalstyletypeid':[-1] + list(range(1,28)),\n",
    "           'buildingclasstypeid':[-1] + list(range(1,6)),\n",
    "            'heatingorsystemtypeid':[-1] + list(range(1,26)),\n",
    "            'pooltypeid10': list(range(-1,2)),\n",
    "            'pooltypeid2': list(range(-1,2)),\n",
    "            'pooltypeid7': list(range(-1,2)),\n",
    "            'propertylandusetypeid': [-1, 31,46,47,246,247,248,260,261,262,263,264,265,266,267,268,269,270,271,\n",
    "                                     273,274,275,276,279,290,291],\n",
    "            'regionidcounty': [2061,3101,1286],\n",
    "            'storytypeid':[-1] + list(range(1,36)),\n",
    "            'typeconstructiontypeid':[-1] + list(range(1,19)),\n",
    "            'yearbuilt': [-1] + list(range(1885,2018)),\n",
    "            'fireplaceflag': [-1] + ['True','False'],\n",
    "            'taxdelinquencyflag': [-1] + ['Y','N']\n",
    "           }.items() if key in cat_atts}\n",
    "\n",
    "# pairs to interact (x1,x2) where x1 is categorical and x2 is continuous\n",
    "interact_pairs = [('regionidcounty','bathroomcnt'),('regionidcounty','bedroomcnt')\n",
    "                 ,('regionidcounty','structuretaxvaluedollarcnt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom transformer, which selects certain variables\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, desired_cols):\n",
    "        self.desired_cols = desired_cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.desired_cols].values\n",
    "\n",
    "# A custom transformer, which first selects the categorical variables\n",
    "# from the DataFrame and then performs the dummification\n",
    "class DF_Selector_GetDummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_dict):\n",
    "        self.cat_dict = cat_dict\n",
    "        self.ndummies = sum(len(c) - 1  for c in cat_dict.values()) \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.fillna(-1) # missing values are given -1 missing label\n",
    "        foo = np.zeros((X.shape[0],self.ndummies))\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for c in sorted(self.cat_dict.keys()):\n",
    "            end += len(self.cat_dict[c]) - 1\n",
    "            foo[:, start:end] = pd.get_dummies(X[c].astype('category', categories=self.cat_dict[c]))[self.cat_dict[c][1:]]\n",
    "            start += len(self.cat_dict[c]) - 1\n",
    "        return foo\n",
    "\n",
    "class Dummify_and_Interact(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, interact_pairs, cat_dict):\n",
    "        self.interact_pairs = interact_pairs\n",
    "        self.cat_dict = cat_dict\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        features = None\n",
    "        for pair in self.interact_pairs:\n",
    "            x1,x2 = pair\n",
    "            # impute x2 if missing\n",
    "            imputer = Imputer()\n",
    "            if np.isnan(X[x2]).any():\n",
    "                x2vals = imputer.fit_transform(X[[x2]])\n",
    "            else:\n",
    "                x2vals = X[[x2]].as_matrix()\n",
    "            # dummify x1 and multiply by x2vals\n",
    "#             bar = ((pd.get_dummies(X[x1].astype('category', \n",
    "#                     categories=self.cat_dict[x1]))[self.cat_dict[x1][1:]]).as_matrix() * x2vals)\n",
    "            bar = pd.get_dummies(X[x1].astype('category'), drop_first=True)\n",
    "            if features is not None:\n",
    "                features = np.concatenate((features,bar),axis=1)\n",
    "            else:\n",
    "                features = bar\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select_and_dummify', DF_Selector_GetDummies(cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_atts)),\n",
    "        ('imputer', Imputer()),\n",
    "    ])\n",
    "\n",
    "# interaction pipeline\n",
    "interact_pipeline = Pipeline([\n",
    "        ('dummify_and_interact',Dummify_and_Interact(interact_pairs, cat_dict)),\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "        (\"interact_pipeline\", interact_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['wts_oct'] = np.where(data['month'] == 10, 1.5, 1)\n",
    "data['wts_nov'] = np.where(data['month'] == 11, 1.5, 1)\n",
    "data['wts_dec'] = np.where(data['month'] == 12, 1.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 90)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(properties)\n",
    "X_train = full_pipeline.transform(data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = data['logerror'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = ElasticNet(alpha=1, l1_ratio = 0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef = ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = np.ones(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when gamma=0.5, alpha should be between 0.1 and 0.001\n",
    "gamma = 0.5\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight[coef != 0] = 1/(abs(coef[coef != 0])**gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_w = X_train/weight[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Lasso(alpha=alpha, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_w, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.coef_ = clf.coef_/weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.18173785e-07,   0.00000000e+00,   1.27821281e-08,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,  -0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,  -0.00000000e+00,\n",
       "        -0.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,  -0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,  -0.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.51507357e-06,  -1.44497447e-04,  -1.03769905e-08,\n",
       "         1.21071386e-04,  -2.23147094e-04,  -2.56125534e-05,\n",
       "        -7.40405402e-10,   3.86200155e-05,  -2.99226541e-05,\n",
       "        -1.12168583e-05,   1.02077246e-04,   2.91585228e-04,\n",
       "        -2.67074523e-04,   1.15114203e-04,   0.00000000e+00,\n",
       "         9.57517013e-07,   0.00000000e+00,   1.09433580e-05,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.85054254e-09,   0.00000000e+00,   1.37441781e-05,\n",
       "         0.00000000e+00,   1.31568127e-05,   2.46301444e-06,\n",
       "         4.36800453e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -1.09475300e-05,   6.43625402e-05,\n",
       "         0.00000000e+00,   0.00000000e+00,  -7.74626377e-07,\n",
       "        -3.18639410e-07,  -1.86020726e-07,  -8.61481672e-06,\n",
       "        -3.91619804e-07,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.41607273e-06,   0.00000000e+00,\n",
       "        -1.62994267e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -2.22351270e-04,   0.00000000e+00,\n",
       "         0.00000000e+00,  -1.09395957e-04,   0.00000000e+00,\n",
       "        -2.15181621e-04,   0.00000000e+00,  -8.20750027e-04,\n",
       "        -9.13921039e-06,   0.00000000e+00,   1.42661307e-05,\n",
       "        -9.05555689e-05,  -1.49128145e-04,  -1.88988174e-04,\n",
       "        -4.21526483e-06,  -9.46421699e-05,   0.00000000e+00,\n",
       "         8.57823022e-05,   4.42123121e-06,   1.05132112e-05,\n",
       "         4.87404410e-04,   1.08010009e-05,   0.00000000e+00,\n",
       "        -9.54459227e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.89261703e-05,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.48447545e-04,   0.00000000e+00,\n",
       "         2.49711877e-04,   1.23085151e-04,   2.49711877e-04,\n",
       "         1.23085151e-04,   2.49711877e-04,   1.23085151e-04])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "prediction using adaptive lass model...\n"
     ]
    }
   ],
   "source": [
    "print(\"predicting\")\n",
    "print(\"prediction using adaptive lass model...\")\n",
    "\n",
    "submission_df = generate_submissions(clf, clf, clf, name=\"Adp-lasso-af\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06346126018645491,\n",
       " 0.06249241099265744,\n",
       " 0.07486079769105185,\n",
       " 0.06557489599687634)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06357440087254919,\n",
       " 0.06264618278176387,\n",
       " 0.07537971498141846,\n",
       " 0.065779331216912304)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge = generate_submissions(oct_enet, oct_enet, oct_enet, name=\"Ridge\")\n",
    "mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06357440087254919,\n",
       " 0.06264618278176387,\n",
       " 0.07537971498141846,\n",
       " 0.065779331216912304)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Enet = generate_submissions(nov_enet, nov_enet, nov_enet, name=\"ElasticNet\")\n",
    "mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06357440087254919,\n",
       " 0.06264618278176387,\n",
       " 0.07537971498141846,\n",
       " 0.065779331216912304)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso = generate_submissions(dec_enet, dec_enet, dec_enet, name=\"Lasso\")\n",
    "mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06221434396363281,\n",
       " 0.06144365500547652,\n",
       " 0.07391738266532494,\n",
       " 0.064432127417700866)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amyhighscore = pd.read_csv(\"9010_XGB_3000_RF.gz\", compression=\"gzip\")\n",
    "mean_absolute_errors(amyhighscore, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.139763</td>\n",
       "      <td>-0.139763</td>\n",
       "      <td>-0.139763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.139977</td>\n",
       "      <td>-0.139977</td>\n",
       "      <td>-0.139977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.214607</td>\n",
       "      <td>0.214607</td>\n",
       "      <td>0.214607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId    201610    201611    201612  201710  201711  201712\n",
       "0  10754147 -0.139763 -0.139763 -0.139763       0       0       0\n",
       "1  10759547 -0.139977 -0.139977 -0.139977       0       0       0\n",
       "2  10843547  0.214607  0.214607  0.214607       0       0       0\n",
       "3  10859147 -0.005250 -0.005250 -0.005250       0       0       0\n",
       "4  10879947  0.003303  0.003303  0.003303       0       0       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.019564</td>\n",
       "      <td>-0.019564</td>\n",
       "      <td>-0.019564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.212738</td>\n",
       "      <td>0.212738</td>\n",
       "      <td>0.212738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId    201610    201611    201612  201710  201711  201712\n",
       "0  10754147 -0.019564 -0.019564 -0.019564       0       0       0\n",
       "1  10759547 -0.019629 -0.019629 -0.019629       0       0       0\n",
       "2  10843547  0.212738  0.212738  0.212738       0       0       0\n",
       "3  10859147  0.016817  0.016817  0.016817       0       0       0\n",
       "4  10879947  0.010969  0.010969  0.010969       0       0       0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Enet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId    201610    201611    201612  201710  201711  201712\n",
       "0  10754147 -0.018543 -0.018543 -0.018543       0       0       0\n",
       "1  10759547 -0.018589 -0.018589 -0.018589       0       0       0\n",
       "2  10843547  0.203752  0.203752  0.203752       0       0       0\n",
       "3  10859147  0.018183  0.018183  0.018183       0       0       0\n",
       "4  10879947  0.010949  0.010949  0.010949       0       0       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Averaging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0627264215390796,\n",
       " 0.06182163198247547,\n",
       " 0.07473668775158138,\n",
       " 0.064978084757667934)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = pd.read_csv(\"RF_n100_maxfeat5_maxdepth8.gz\", compression=\"gzip\")\n",
    "mean_absolute_errors(RF, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06195625879043588,\n",
       " 0.06436095290251921,\n",
       " 0.07321730879815982,\n",
       " 0.064762854132521586)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_2 = pd.read_csv(\"RF_n100_maxfeat10_maxdepth20_extreme.gz\", compression=\"gzip\")\n",
    "mean_absolute_errors(RF_2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06211727600763514,\n",
       " 0.06136520946002188,\n",
       " 0.07414289916043706,\n",
       " 0.064404712807773379)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = pd.read_csv(\"XGB_600.gz\", compression=\"gzip\")\n",
    "mean_absolute_errors(XGB, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05998706659714675,\n",
       " 0.05918412810186208,\n",
       " 0.07170160296434737,\n",
       " 0.06220029687696086)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB3000 = pd.read_csv(\"XGB_3000.csv\")\n",
    "mean_absolute_errors(XGB3000, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06268473765862069,\n",
       " 0.061797918439336595,\n",
       " 0.07437674098281555,\n",
       " 0.064875449656555853)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend3 = submission_df[['ParcelId']].copy()\n",
    "cols = ['201610','201611','201612','201710','201711','201712']\n",
    "blend3 = pd.concat([blend3,(20/100)*Ridge[cols] + (20/100)*Enet[cols] + (20/100)*Lasso[cols] +\n",
    "                    (18/100)*XGB[cols] + (18/100)*RF[cols] + (2/100)*XGB3000[cols]\n",
    "                   +(2/100)*RF_2[cols]], axis=1)\n",
    "blend3['ParcelId'] = blend3['ParcelId'].astype(int)\n",
    "assert all(blend3.ParcelId.unique() == submission_df.ParcelId.unique())\n",
    "mean_absolute_errors(blend3, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend3.to_csv(\"new_ensemble_2.gz\", index=False, float_format='%.4g', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"theilson.gz\", index=False, float_format='%.4g', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
