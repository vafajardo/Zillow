{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maindir = \"/home/anerdi/Desktop/Zillow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anerdi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# linux\n",
    "logerror = pd.read_csv(maindir + \"/data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "logerror['weeknumber'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])\n",
    "logerror['month'] = logerror['transactiondate'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "properties = pd.read_csv(maindir + \"/data/properties_2016.csv/properties_2016.csv\")\n",
    "test_parcels = pd.read_csv(maindir + \"/data/sample_submission.csv\", usecols = ['ParcelId'])\n",
    "test_parcels.rename(columns={'ParcelId':'parcelid'}, inplace=True)\n",
    "\n",
    "# join on parcel id\n",
    "data = pd.merge(properties,logerror[['parcelid','logerror','month']], on='parcelid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, Imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcelid', 'airconditioningtypeid', 'architecturalstyletypeid',\n",
       "       'basementsqft', 'bathroomcnt', 'bedroomcnt', 'buildingclasstypeid',\n",
       "       'buildingqualitytypeid', 'calculatedbathnbr', 'decktypeid',\n",
       "       'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet',\n",
       "       'finishedsquarefeet12', 'finishedsquarefeet13', 'finishedsquarefeet15',\n",
       "       'finishedsquarefeet50', 'finishedsquarefeet6', 'fips', 'fireplacecnt',\n",
       "       'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'hashottuborspa',\n",
       "       'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet',\n",
       "       'poolcnt', 'poolsizesum', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7',\n",
       "       'propertycountylandusecode', 'propertylandusetypeid',\n",
       "       'propertyzoningdesc', 'rawcensustractandblock', 'regionidcity',\n",
       "       'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt',\n",
       "       'storytypeid', 'threequarterbathnbr', 'typeconstructiontypeid',\n",
       "       'unitcnt', 'yardbuildingsqft17', 'yardbuildingsqft26', 'yearbuilt',\n",
       "       'numberofstories', 'fireplaceflag', 'structuretaxvaluedollarcnt',\n",
       "       'taxvaluedollarcnt', 'assessmentyear', 'landtaxvaluedollarcnt',\n",
       "       'taxamount', 'taxdelinquencyflag', 'taxdelinquencyyear',\n",
       "       'censustractandblock', 'logerror', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup variables considered in the model\n",
    "\n",
    "# numerical variables\n",
    "num_atts = ['bathroomcnt','bedroomcnt','buildingqualitytypeid','calculatedbathnbr','finishedfloor1squarefeet',\n",
    "           'calculatedfinishedsquarefeet','finishedsquarefeet12','finishedsquarefeet13',\n",
    "           'finishedsquarefeet15','finishedsquarefeet50','finishedsquarefeet6','fireplacecnt',\n",
    "           'fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude','lotsizesquarefeet',\n",
    "           'poolcnt','poolsizesum','censustractandblock','roomcnt','threequarterbathnbr','unitcnt',\n",
    "           'yardbuildingsqft17','yardbuildingsqft26','numberofstories',\n",
    "            'structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount']\n",
    "\n",
    "# categorical variables\n",
    "cat_atts = ['airconditioningtypeid','architecturalstyletypeid',\n",
    "           'buildingclasstypeid','heatingorsystemtypeid','pooltypeid10','pooltypeid2',\n",
    "            'pooltypeid7','propertylandusetypeid','rawcensustractandblock','regionidcounty','regionidcity',\n",
    "            'regionidzip','regionidneighborhood',\n",
    "           'storytypeid','typeconstructiontypeid','yearbuilt','fireplaceflag',\n",
    "           'taxdelinquencyflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    X = data[num_atts + cat_atts].copy()\n",
    "    # fill in missing values\n",
    "    for c in num_atts:\n",
    "        X[c].fillna(X[c].mean(skipna=True), inplace=True)\n",
    "        X[c] = X[c].astype('float32')\n",
    "\n",
    "    for c in cat_atts:\n",
    "        if X[c].dtype == object:\n",
    "    #         print(c)\n",
    "            X[c].fillna(\"-1\", inplace=True)\n",
    "            X[c] = X[c].astype(str)\n",
    "        else:\n",
    "            X[c].fillna(-1, inplace=True)\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(X[c].values))\n",
    "        X[c] = lbl.transform(X[c])\n",
    "        X[c] = X[c].astype('float32')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_submissions(oct_model,nov_model,dec_model,name='new_submission'):\n",
    "#     \"\"\"\n",
    "#     This function creates the submission file for the public leaderboard predictions.\n",
    "#     Three already fitted models, one for each of the predicting time points, is required.\n",
    "#     \"\"\"\n",
    "#     models = {'201610': oct_model, '201611': nov_model, '201612': dec_model}\n",
    "#     submission_df = DataFrame()\n",
    "#     for i in range(int(properties.shape[0] / 100000)):\n",
    "#         subset = properties.iloc[i*100000:(i+1)*100000].copy()\n",
    "#         predictions = {}\n",
    "#         for mm in range(10,13):\n",
    "#             subset['month'] = mm\n",
    "#             all_feats = preprocess(subset)\n",
    "#             predictions['2016{x}'.format(x=mm)] = models['2016{x}'.format(x=mm)].predict(all_feats)\n",
    "#         foo = subset[['parcelid']].reset_index(drop=True)\n",
    "#         foo = pd.concat([foo, DataFrame(predictions)], axis=1)\n",
    "# #         foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "# #                                                         '201611': nov_model.predict(all_feats),\n",
    "# #                                                         '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "#         submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "#     #  fencepost problem\n",
    "#     subset = properties.iloc[2900000:].copy()\n",
    "#     predictions = {}\n",
    "#     for mm in range(10,13):\n",
    "#         subset['month'] = mm\n",
    "#         all_feats = preprocess(subset)\n",
    "#         predictions['2016{x}'.format(x=mm)] = models['2016{x}'.format(x=mm)].predict(all_feats)\n",
    "#     foo = subset[['parcelid']].reset_index(drop=True)\n",
    "#     foo = pd.concat([foo, DataFrame(predictions)], axis=1)\n",
    "# #     foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "# #                                                     '201611': nov_model.predict(all_feats),\n",
    "# #                                                     '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "#     submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "#     submission_df['201710'] = 0\n",
    "#     submission_df['201711'] = 0\n",
    "#     submission_df['201712'] = 0\n",
    "    \n",
    "#     submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "#     submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "#                                                                                            '201710','201711','201712']].round(4)\n",
    "#     # unit test\n",
    "#     submission_df.drop_duplicates(inplace=True)\n",
    "#     assert submission_df.shape[0] == properties.shape[0]\n",
    "#     # write to .csv\n",
    "#     submission_df[['ParcelId','201610','201611','201612',\n",
    "#                   '201710','201711','201712']].to_csv(name + \".csv\", index=False)\n",
    "#     return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submissions(oct_model,nov_model,dec_model,name='new_submission',logy=True):\n",
    "    \"\"\"\n",
    "    This function creates the submission file for the public leaderboard predictions.\n",
    "    Three already fitted models, one for each of the predicting time points, is required.\n",
    "    \"\"\"\n",
    "    submission_df = DataFrame()\n",
    "    for i in range(int(properties.shape[0] / 100000)):\n",
    "        all_feats = preprocess(properties.iloc[i*100000:(i+1)*100000])\n",
    "        foo = properties.iloc[i*100000:(i+1)*100000][['parcelid']].reset_index(drop=True)\n",
    "        if logy:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                            '201611': nov_model.predict(all_feats),\n",
    "                                                            '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "        else:\n",
    "            foo = pd.concat([foo, DataFrame({'201610': np.log(oct_model.predict(all_feats)),\n",
    "                                                            '201611': np.log(nov_model.predict(all_feats)),\n",
    "                                                            '201612': np.log(dec_model.predict(all_feats))})], axis=1)\n",
    "        submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "\n",
    "    #  fencepost problem\n",
    "    all_feats = preprocess(properties.iloc[2900000:])\n",
    "    foo = properties.iloc[2900000:][['parcelid']].reset_index(drop=True)\n",
    "    foo = pd.concat([foo, DataFrame({'201610': oct_model.predict(all_feats),\n",
    "                                                    '201611': nov_model.predict(all_feats),\n",
    "                                                    '201612': dec_model.predict(all_feats)})], axis=1)\n",
    "    submission_df = pd.concat([submission_df, foo], ignore_index=True)\n",
    "    \n",
    "    submission_df['201710'] = 0\n",
    "    submission_df['201711'] = 0\n",
    "    submission_df['201712'] = 0\n",
    "    \n",
    "    submission_df.rename(columns={'parcelid':'ParcelId'}, inplace=True)    \n",
    "    submission_df[['201610','201611','201612','201710','201711','201712']]= submission_df[['201610','201611','201612',\n",
    "                                                                                           '201710','201711','201712']].round(4)\n",
    "    # unit test\n",
    "    submission_df.drop_duplicates(inplace=True)\n",
    "    assert submission_df.shape[0] == properties.shape[0]\n",
    "    # write to .csv\n",
    "    submission_df[['ParcelId','201610','201611','201612',\n",
    "                  '201710','201711','201712']].to_csv(name + \".csv\", index=False)\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_errors(submission_df, comparison_df):\n",
    "    \"\"\"\n",
    "    This function takes a submission entry for public leaderboard, and returns\n",
    "    the training error for each month.\n",
    "    \"\"\"\n",
    "    # training error\n",
    "    trainresults = pd.merge(submission_df[['ParcelId','201610','201611','201612']], comparison_df[['parcelid','logerror','month']],\n",
    "                           left_on='ParcelId', right_on='parcelid')\n",
    "    oct_error = abs(trainresults[trainresults['month'] == 10]['201610'] \n",
    "                    - trainresults[trainresults['month'] == 10]['logerror']).mean()\n",
    "    nov_error = abs(trainresults[trainresults['month'] == 11]['201611'] \n",
    "                    - trainresults[trainresults['month'] == 11]['logerror']).mean()\n",
    "    dec_error = abs(trainresults[trainresults['month'] == 12]['201612'] \n",
    "                    - trainresults[trainresults['month'] == 12]['logerror']).mean()\n",
    "    overall_mae = (oct_error*(trainresults['month'] == 10).sum() + nov_error*(trainresults['month'] == 11).sum() \n",
    "                        + dec_error*(trainresults['month'] == 12).sum()) / (trainresults['month'].isin([10,11,12])).sum()\n",
    "    return (oct_error, nov_error, dec_error, overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p75 = np.percentile(data['logerror'],75)\n",
    "p25 = np.percentile(data['logerror'],25)\n",
    "extremelogerrors = ((data['logerror'] >= p75) | (data['logerror'] <= p25))*1\n",
    "data['wts_oct'] = extremelogerrors + np.where(data['month'] == 10, 1.5, 1)\n",
    "data['wts_nov'] = np.where(data['month'] == 11, 1.5, 1)\n",
    "data['wts_dec'] = np.where(data['month'] == 12, 1.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata, testdata = train_test_split(data, test_size = 0.2, random_state=9)\n",
    "traindata = traindata.reset_index(drop=True)\n",
    "testdata = testdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = preprocess(data)\n",
    "Y_train = data['logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid = dict(max_depth=[5,10,15,20,25])\n",
    "\n",
    "# oct_gs = GridSearchCV(RandomForestRegressor(random_state=42, n_estimators = 200, max_features = 9),\n",
    "#                       param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# nov_gs = GridSearchCV(RandomForestRegressor(random_state=42, n_estimators = 200, max_features = 9),\n",
    "#                       param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# dec_gs = GridSearchCV(RandomForestRegressor(random_state=42, n_estimators = 200, max_features = 9),\n",
    "#                       param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# print(\"Training\")\n",
    "# print(\"training oct model...\")\n",
    "# oct_gs.fit(X_train,Y_train, sample_weight=data['wts_oct'])\n",
    "# print(\"training nov model...\")\n",
    "# nov_gs.fit(X_train,Y_train, sample_weight=data['wts_nov'])\n",
    "# print(\"training dec model...\")\n",
    "# dec_gs.fit(X_train,Y_train, sample_weight=data['wts_nov'])\n",
    "\n",
    "# submission_df = generate_submissions(oct_gs.best_estimator_, \n",
    "#                                      nov_gs.best_estimator_, \n",
    "#                                      dec_gs.best_estimator_, name =\"RF_submission_mean\")\n",
    "# mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=35,\n",
       "           max_features=9, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=42,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_regr_rf = RandomForestRegressor(n_estimators = 100, max_features = 9, random_state=42, max_depth=35, criterion='mse')\n",
    "nov_regr_rf = RandomForestRegressor(n_estimators = 100, max_features = 9, random_state=42, max_depth=35, criterion='mse')\n",
    "dec_regr_rf = RandomForestRegressor(n_estimators = 100, max_features = 9, random_state=42, max_depth=35, criterion='mse')\n",
    "\n",
    "oct_regr_rf.fit(X_train,Y_train, sample_weight=data['wts_oct'])\n",
    "nov_regr_rf.fit(X_train,Y_train, sample_weight=data['wts_nov'])\n",
    "dec_regr_rf.fit(X_train,Y_train, sample_weight=data['wts_dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = generate_submissions(oct_regr_rf, nov_regr_rf, dec_regr_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.0444</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>-0.0269</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId  201610  201611  201612  201710  201711  201712\n",
       "0  10754147  0.0712  0.1548  0.0899       0       0       0\n",
       "1  10759547 -0.0444  0.0120 -0.0269       0       0       0\n",
       "2  10843547  0.0310 -0.0269  0.0686       0       0       0\n",
       "3  10859147  0.2890  0.1305  0.1478       0       0       0\n",
       "4  10879947  0.2394  0.1818  0.1399       0       0       0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.052186437613020095,\n",
       " 0.05355925520262865,\n",
       " 0.06255405405405404,\n",
       " 0.054590564270662709)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_errors(submission_df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201610    0.049015\n",
       "201611    0.050554\n",
       "201612    0.049034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[['201610','201611','201612']].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Averaging: XGB + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB = pd.read_csv(\"XGB_3000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.715665e-02</td>\n",
       "      <td>1.743313e-02</td>\n",
       "      <td>1.726862e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.656845e-02</td>\n",
       "      <td>6.871725e-02</td>\n",
       "      <td>6.613157e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.266000e+00</td>\n",
       "      <td>-2.233000e+00</td>\n",
       "      <td>-2.214000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.449000e-03</td>\n",
       "      <td>4.359000e-03</td>\n",
       "      <td>4.401000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.279000e-02</td>\n",
       "      <td>1.277000e-02</td>\n",
       "      <td>1.278000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.281000e-02</td>\n",
       "      <td>2.284000e-02</td>\n",
       "      <td>2.289000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.834000e+00</td>\n",
       "      <td>3.803000e+00</td>\n",
       "      <td>3.868000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             201610        201611        201612\n",
       "count  2.985217e+06  2.985217e+06  2.985217e+06\n",
       "mean   1.715665e-02  1.743313e-02  1.726862e-02\n",
       "std    6.656845e-02  6.871725e-02  6.613157e-02\n",
       "min   -2.266000e+00 -2.233000e+00 -2.214000e+00\n",
       "25%    4.449000e-03  4.359000e-03  4.401000e-03\n",
       "50%    1.279000e-02  1.277000e-02  1.278000e-02\n",
       "75%    2.281000e-02  2.284000e-02  2.289000e-02\n",
       "max    3.834000e+00  3.803000e+00  3.868000e+00"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB[['201610','201611','201612']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05998706659714675,\n",
       " 0.05918412810186208,\n",
       " 0.07170160296434737,\n",
       " 0.06220029687696086)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_errors(XGB, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05430681879987949,\n",
       " 0.054777713722343975,\n",
       " 0.06490518643041981,\n",
       " 0.05656512077107239)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend = (((1/2)*submission_df + (1/2)*XGB))\n",
    "blend['ParcelId'] = blend['ParcelId'].astype(int)\n",
    "assert all(blend.ParcelId.unique() == submission_df.ParcelId.unique())\n",
    "mean_absolute_errors(blend, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.665456e-02</td>\n",
       "      <td>1.862669e-02</td>\n",
       "      <td>2.154185e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.856857e-02</td>\n",
       "      <td>5.005677e-02</td>\n",
       "      <td>4.817773e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.102850e+00</td>\n",
       "      <td>-2.118050e+00</td>\n",
       "      <td>-2.022400e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.310000e-03</td>\n",
       "      <td>3.860000e-03</td>\n",
       "      <td>6.726600e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.398300e-02</td>\n",
       "      <td>1.600500e-02</td>\n",
       "      <td>1.910500e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.684500e-02</td>\n",
       "      <td>2.834000e-02</td>\n",
       "      <td>3.210000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.429000e+00</td>\n",
       "      <td>3.340500e+00</td>\n",
       "      <td>3.319050e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             201610        201611        201612\n",
       "count  2.985217e+06  2.985217e+06  2.985217e+06\n",
       "mean   1.665456e-02  1.862669e-02  2.154185e-02\n",
       "std    4.856857e-02  5.005677e-02  4.817773e-02\n",
       "min   -2.102850e+00 -2.118050e+00 -2.022400e+00\n",
       "25%    1.310000e-03  3.860000e-03  6.726600e-03\n",
       "50%    1.398300e-02  1.600500e-02  1.910500e-02\n",
       "75%    2.684500e-02  2.834000e-02  3.210000e-02\n",
       "max    3.429000e+00  3.340500e+00  3.319050e+00"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend[['201610','201611','201612']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend.to_csv(\"XGB_RF_overfit.gz\", index=False, float_format='%.4g', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06266067912397041,\n",
       " 0.0618791894852136,\n",
       " 0.07436026451983876,\n",
       " 0.064875450714118515)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = pd.read_csv(\"RF_submission_mean.csv\")\n",
    "mean_absolute_errors(RF, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985217, 7)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2985217"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend2.ParcelId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blend2 = submission_df[['ParcelId']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06053106576640541,\n",
       " 0.05996690064151146,\n",
       " 0.07188351468688907,\n",
       " 0.062721623382264072)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['201610','201611','201612','201710','201711','201712']\n",
    "blend2 = pd.concat([blend2,(1/10)*submission_df[cols] + (1/10)*XGB[cols] + (8/10)*RF[cols]], axis=1)\n",
    "blend2['ParcelId'] = blend2['ParcelId'].astype(int)\n",
    "assert all(blend2.ParcelId.unique() == submission_df.ParcelId.unique())\n",
    "mean_absolute_errors(blend2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.174630</td>\n",
       "      <td>0.184297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.013062</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.254780</td>\n",
       "      <td>0.206110</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.221960</td>\n",
       "      <td>0.190970</td>\n",
       "      <td>0.203410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.071535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId    201610    201611    201612  201710  201711  201712\n",
       "0  10754147  0.125112  0.174630  0.184297     0.0     0.0     0.0\n",
       "1  10759547 -0.013062 -0.002501 -0.008912     0.0     0.0     0.0\n",
       "2  10843547  0.254780  0.206110  0.172340     0.0     0.0     0.0\n",
       "3  10859147  0.221960  0.190970  0.203410     0.0     0.0     0.0\n",
       "4  10879947  0.039744  0.012240  0.071535     0.0     0.0     0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blend2.to_csv(\"XGB_RF_RF_overfit.gz\", index=False, float_format='%.4g', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
